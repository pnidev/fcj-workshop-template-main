[
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Phạm Thị Yến Nhi\nSố điện thoại: 0901143200\nEmail: xpnhi023@gmail.com\nTrường: Đại Học FPT\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 8/09/2025 đến ngày 9/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 1: Làm quen với giao diện AWS Console và các khái niệm nền tảng. Tự tạo và cấu hình tài khoản AWS Free Tier, kèm bảo mật với MFA. Tìm hiểu cách quản lý chi phí bằng AWS Budgets \u0026amp; Billing Alarm. Bước đầu tiếp cận IAM và phương pháp phân quyền an toàn. Công việc thực hiện trong tuần: Ngày Công việc Bắt đầu Hoàn thành Tài liệu tham khảo 1 - Đăng ký tài khoản AWS - Bật bảo mật MFA cho tài khoản root - Tạo cảnh báo chi phí ban đầu 09/09/2025 09/09/2025 https://000001.awsstudygroup.com/vi/ 2 - Tạo AWS Budget theo hạn mức - Cấu hình email cảnh báo chi tiêu - Làm quen giao diện Billing 10/09/2025 10/09/2025 https://000007.awsstudygroup.com/vi/ 3 - Khảo sát các gói AWS Support + Basic / Developer / Business - So sánh thời gian phản hồi hỗ trợ 11/09/2025 11/09/2025 https://000009.awsstudygroup.com/vi/1-support-plans/ 4 - Nắm vững khái niệm IAM Users – Groups - Tìm hiểu Policy JSON cơ bản 12/09/2025 12/09/2025 https://000002.awsstudygroup.com/vi/ 5 - Bài thực hành nhỏ: + Kích hoạt MFA cho User + Test phân quyền IAM + Tạo S3 bucket và xóa sau kiểm thử 13/09/2025 13/09/2025 https://000057.awsstudygroup.com/vi/ Kết quả đạt được: Hoàn thiện việc tạo và cấu hình bảo mật tài khoản AWS, tránh rủi ro truy cập. Biết cách đặt Budget giới hạn chi phí, theo dõi Free Tier hiệu quả. Hiểu rõ từng loại AWS Support Plan và tình huống sử dụng. Thành thạo các thao tác cơ bản của IAM: tạo user, cấp quyền, thử nghiệm policy. Thực hành thao tác với S3 bucket và đánh giá mức độ tiêu tốn tài nguyên. Tổng kết: Sau tuần đầu tiên thực tập, tôi đã:\nSử dụng AWS Console thành thạo hơn. Chủ động quản lý tài khoản cùng hệ thống cảnh báo chi phí. Thiết lập ngân sách Free Tier và theo dõi mức sử dụng. Vận dụng IAM trong bài toán phân quyền thực tế. Tự tin thao tác với S3 và hiểu cơ chế tính phí cơ bản. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "This section documents toàn bộ hành trình học AWS trong 12 tuần liên tiếp.\nLộ trình được thiết kế theo dạng tăng tiến — từ căn bản về quản lý tài khoản đến thiết kế hệ thống thực chiến với tính sẵn sàng cao.\nPhương pháp triển khai Tôi bắt đầu học từ ngày 9/9/2025 và duy trì việc học đều đặn mỗi tuần 5 buổi.\nMỗi ngày dành trung bình 2–3 giờ thực hành trực tiếp trên AWS Console, đọc tài liệu chính thống và triển khai bài lab từ chương trình First Cloud Journey (FCJ).\nTimeline chương trình: 12 tuần liên tục — tương đương một quý học tập thực hành.\nCách tiếp cận học tập:\n60% thực hành trực tiếp trên AWS (deploy, cấu hình, xử lý lỗi) 30% đọc tài liệu, hiểu kiến trúc, nghiên cứu best practices 10% tổng hợp, hệ thống hóa kiến thức \u0026amp; làm bài mini-challenge Progress Overview Trong 12 tuần, tôi dần hình thành nền tảng cloud vững chắc, triển khai hơn 25 dịch vụ AWS và hoàn thiện một hệ thống hoàn chỉnh ở cuối khóa.\nDưới đây là danh sách các tuần học — mỗi tuần có worklog chi tiết:\nWeek 1: Khởi tạo \u0026amp; quản lý tài khoản AWS: Billing, Budgets, IAM\nWeek 2: Networking căn bản: VPC, Subnet, Route, Security \u0026amp; CLI\nWeek 3: EC2 \u0026amp; Compute: Instance, IAM Role, Cloud9 Workspace\nWeek 4: Storage \u0026amp; Hosting: S3 Static Website, Lightsail, Containers\nWeek 5: Database cơ bản với Amazon RDS \u0026amp; DynamoDB\nWeek 6: Caching \u0026amp; Performance: ElastiCache + 3-Tier Architecture\nWeek 7: Scaling \u0026amp; Monitoring: Auto Scaling + CloudWatch Alerts\nWeek 8: Global Delivery: Route 53, CloudFront, Lambda@Edge\nWeek 9: Windows Workloads — EC2 Windows, Managed AD\nWeek 10: Hybrid Directory — AD Connector \u0026amp; Enterprise Identity\nWeek 11: High Availability — Load Balancing, Multi-AZ \u0026amp; DR\nWeek 12: Capstone — Deploy Full Architecture + Certification Prep\nMajor Takeaways Nắm vững 25+ dịch vụ AWS liên quan compute, network, database, security Thiết kế kiến trúc high-availability, fault tolerant, scalable Tối ưu chi phí, giám sát tài nguyên và log hệ thống hiệu quả Làm quen môi trường Windows Server \u0026amp; directory enterprise Hoàn thiện capstone thực chiến tổng hợp toàn bộ kiến thức Future Goals Ôn thi và hướng đến AWS Solutions Architect – Associate Tiếp tục đào sâu serverless: Lambda, Step Functions, EventBridge Tham gia community, đóng góp project open-source và workshop thực chiến "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-api-gateway-lambda/5.4.1-rest-api/",
	"title": "API Gateway rest",
	"tags": [],
	"description": "",
	"content": "REST API Gateway Chúng ta sẽ tạo REST API để kết nối frontend với backend Lambda.\nCác route cần có:\nPOST /score GET /leaderboard GET /leaderboard/global POST /progress POST /unlock POST /task/complete POST /money/add POST /shop/buy POST /avatar/presign POST /avatar/update POST /avatar/process ← gọi Lambda container để xử lý ảnh Cấu hình:\nBật CORS cho tất cả route. Tạo JWT Authorizer trỏ đến Cognito. Gán mỗi route vào đúng Lambda function. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTruy vấn Amazon Aurora PostgreSQL bằng cách sử dụng Amazon Bedrock Knowledge Bases với dữ liệu có cấu trúc Amazon Bedrock Knowledge Bases cung cấp tính năng Retrieval Augmented Generation (RAG) được quản lý hoàn toàn, cho phép kết nối Large Language Models (LLMs) với các nguồn dữ liệu nội bộ.Tính năng này giúp cải thiện đầu ra của Foundation Models (FMs) bằng cách bổ sung ngữ cảnh từ dữ liệu riêng tư, làm cho phản hồi trở nên chính xác và phù hợp hơn.\nTại AWS re:Invent 2024, AWS công bố rằng Amazon Bedrock Knowledge Bases hiện hỗ trợ truy vấn ngôn ngữ tự nhiên (natural language querying) để truy xuất dữ liệu có cấu trúc (structured data) từ Amazon Redshift và Amazon SageMaker Lakehouse. Tính năng này mang đến một quy trình quản lý đầy đủ để xây dựng các ứng dụng Generative AI có khả năng truy cập và tích hợp thông tin từ cả nguồn dữ liệu có cấu trúc và phi cấu trúc. Bằng cách sử dụng Natural Language Processing (NLP), Amazon Bedrock Knowledge Bases có thể chuyển đổi truy vấn ngôn ngữ tự nhiên thành câu lệnh SQL, cho phép người dùng truy xuất dữ liệu trực tiếp từ các nguồn được hỗ trợ mà không cần hiểu cấu trúc cơ sở dữ liệu hay cú pháp SQL.\nBài viết này sẽ hướng dẫn cách làm cho dữ liệu trong Amazon Aurora PostgreSQL-Compatible Edition có thể được truy vấn bằng ngôn ngữ tự nhiên thông qua Amazon Bedrock Knowledge Bases, đồng thời duy trì tính cập nhật của dữ liệu (data freshness).\nStructured data retrieval trong Amazon Bedrock Knowledge Bases và Amazon Redshift Zero-ETL Structured data retrieval trong Amazon Bedrock Knowledge Bases cho phép tương tác bằng natural language với database của bạn bằng cách convert các user queries thành các SQL statements. Khi bạn connect một supported data source như Amazon Redshift, Amazon Bedrock Knowledge Bases sẽ analyze database schema, table relationships, query engine, và các historical queries để hiểu context và structure của thông tin của bạn. Hiểu biết này cho phép service tạo ra các SQL queries chính xác từ các natural language questions.\nTại thời điểm viết bài, Amazon Bedrock Knowledge Bases hỗ trợ structured data retrieval trực tiếp từ Amazon Redshift và SageMaker Lakehouse. Mặc dù direct support cho Aurora PostgreSQL-Compatible hiện tại chưa có, bạn có thể sử dụng zero-ETL integration giữa Aurora PostgreSQL-Compatible và Amazon Redshift để làm cho dữ liệu của bạn có thể truy cập được bởi Amazon Bedrock Knowledge Bases structured data retrieval. Zero-ETL integration tự động replicate các Aurora PostgreSQL tables sang Amazon Redshift gần như trong thời gian thực, giúp alleviate nhu cầu về các complex extract, transform, and load (ETL) pipelines hoặc các data movement processes.\nArchitectural pattern này đặc biệt có giá trị cho các tổ chức muốn enable natural language querying đối với structured application data được lưu trữ trong các Amazon Aurora database tables. Bằng cách kết hợp zero-ETL integration với Amazon Bedrock Knowledge Bases, bạn có thể tạo ra các powerful applications như AI assistants sử dụng LLMs để cung cấp natural language responses dựa trên operational data của họ.\nSolution overview Sơ đồ sau minh họa architecture mà chúng ta sẽ triển khai để connect Aurora PostgreSQL-Compatible với Amazon Bedrock Knowledge Bases sử dụng zero-ETL. Workflow bao gồm các bước sau: Dữ liệu được lưu trữ trong Aurora PostgreSQL-Compatible bên trong private subnet. Chúng tôi sử dụng bastion host để connect securely đến database từ public subnet.\nSử dụng zero-ETL integration, dữ liệu này được đưa vào Amazon Redshift, cũng nằm trong private subnet.\nAmazon Bedrock Knowledge Bases sử dụng Amazon Redshift làm structured data source.\nNgười dùng có thể tương tác với Amazon Bedrock Knowledge Bases thông qua AWS Management Console hoặc AWS SDK client, gửi các natural language queries. Các queries này được processed bởi Amazon Bedrock Knowledge Bases để retrieve information được lưu trữ trong Amazon Redshift (nguồn từ Aurora).\nPrerequisites Đảm bảo bạn đã logged in với user role có quyền để: Tạo một Aurora database, chạy các DDL (CREATE, ALTER, DROP, RENAME) và DML (SELECT, INSERT, UPDATE, DELETE) statements\nTạo một Redshift database\nThiết lập zero-ETL integration\nTạo một Amazon Bedrock knowledge base\nThiết lập Aurora PostgreSQL database Trong phần này, chúng ta sẽ đi qua việc tạo và cấu hình một Aurora PostgreSQL database với một sample schema để minh họa cho bài hướng dẫn. Chúng ta sẽ tạo ba bảng liên kết với nhau: products, customers, và orders.\nProvision the database Trong phần này, chúng ta sẽ đi qua việc tạo và cấu hình một Aurora PostgreSQL database với một sample schema để minh họa cho bài hướng dẫn. Chúng ta sẽ tạo ba bảng liên kết với nhau: products, customers, và orders. Provision the database Bắt đầu bằng việc thiết lập môi trường database. Tạo một Aurora PostgreSQL database cluster mới và khởi chạy một Amazon Elastic Compute Cloud (Amazon EC2) instance để làm điểm truy cập quản lý database. EC2 instance sẽ giúp tạo bảng và quản lý dữ liệu một cách thuận tiện trong suốt bài hướng dẫn này. Hình screenshot sau đây hiển thị chi tiết của database cluster và EC2 instance. Để được hướng dẫn thiết lập database của bạn, tham khảo Creating and connecting to an Aurora PostgreSQL DB cluster. Tạo database schema Sau khi bạn kết nối đến database bằng SSH trên EC2 instance của mình (được mô tả trong Creating and connecting to an Aurora PostgreSQL DB cluster), đã đến lúc tạo cấu trúc dữ liệu. Chúng ta sẽ sử dụng các DDL statements sau để tạo ba bảng: \u0026ndash; Create Product table CREATE TABLE product ( product_id SERIAL PRIMARY KEY, product_name VARCHAR(100) NOT NULL, price DECIMAL(10, 2) NOT NULL );\n\u0026ndash; Create Customer table CREATE TABLE customer ( customer_id SERIAL PRIMARY KEY, customer_name VARCHAR(100) NOT NULL, pincode VARCHAR(10) NOT NULL );\n\u0026ndash; Create Orders table CREATE TABLE orders ( order_id SERIAL PRIMARY KEY, product_id INTEGER NOT NULL, customer_id INTEGER NOT NULL, FOREIGN KEY (product_id) REFERENCES product(product_id), FOREIGN KEY (customer_id) REFERENCES customer(customer_id) );\nĐiền dữ liệu vào các bảng Sau khi tạo các bảng, bạn có thể điền dữ liệu mẫu vào chúng. Khi chèn dữ liệu vào bảng orders, hãy nhớ duy trì referential integrity bằng cách kiểm tra: product_id tồn tại trong bảng product và customer_id tồn tại trong bảng customer.\nVí dụ mã để điền dữ liệu vào các bảng như sau:\nINSERT INTO product (product_id, product_name, price) VALUES (1, \u0026lsquo;Smartphone X\u0026rsquo;, 699.99); INSERT INTO product (product_id, product_name, price) VALUES (2, \u0026lsquo;Laptop Pro\u0026rsquo;, 1299.99); INSERT INTO product (product_id, product_name, price) VALUES (3, \u0026lsquo;Wireless Earbuds\u0026rsquo;, 129.99); INSERT INTO customer (customer_id, customer_name, pincode) VALUES (1, \u0026lsquo;John Doe\u0026rsquo;, \u0026lsquo;12345\u0026rsquo;); INSERT INTO customer (customer_id, customer_name, pincode) VALUES (2, \u0026lsquo;Jane Smith\u0026rsquo;, \u0026lsquo;23456\u0026rsquo;); INSERT INTO customer (customer_id, customer_name, pincode) VALUES (3, \u0026lsquo;Robert Johnson\u0026rsquo;, \u0026lsquo;34567\u0026rsquo;); INSERT INTO orders (order_id, product_id, customer_id) VALUES (1, 1, 1); INSERT INTO orders (order_id, product_id, customer_id) VALUES (2, 1, 2); INSERT INTO orders (order_id, product_id, customer_id) VALUES (3, 2, 3); INSERT INTO orders (order_id, product_id, customer_id) VALUES (4, 2, 1); INSERT INTO orders (order_id, product_id, customer_id) VALUES (5, 3, 2); INSERT INTO orders (order_id, product_id, customer_id) VALUES (6, 3, 3);\nHãy đảm bảo duy trì referential integrity khi điền dữ liệu vào bảng orders để tránh vi phạm foreign key constraint.\nBạn cũng có thể sử dụng các ví dụ tương tự để xây dựng schema và điền dữ liệu cho các bảng khác.\nStaging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Thiết lập Redshift cluster và cấu hình zero-ETL Sau khi thiết lập xong Aurora PostgreSQL database, bạn có thể thiết lập zero-ETL integration với Amazon Redshift. Tích hợp này tự động đồng bộ dữ liệu giữa Aurora PostgreSQL-Compatible và Amazon Redshift.\nThiết lập Amazon Redshift Trước tiên, tạo một Amazon Redshift Serverless workgroup và namespace. Tham khảo hướng dẫn tại Creating a data warehouse with Amazon Redshift Serverless.\nTạo zero-ETL integration Quy trình zero-ETL integration bao gồm hai bước chính:\n1.Tạo zero-ETL integration từ Aurora PostgreSQL database sang Redshift Serverless. 2.Sau khi thiết lập tích hợp trên Aurora, tạo mapping database tương ứng trong Amazon Redshift. Bước này quan trọng để đảm bảo đồng bộ dữ liệu chính xác giữa hai dịch vụ.\nẢnh chụp màn hình sau minh họa chi tiết về zero-ETL integration của chúng tôi. Xác minh tích hợp Sau khi hoàn thành việc tích hợp, bạn có thể xác minh thành công của nó thông qua một số kiểm tra.\nTrước hết, bạn có thể kiểm tra chi tiết zero-ETL integration trong Amazon Redshift console. Bạn sẽ thấy trạng thái Active cho tích hợp của mình, cùng với thông tin nguồn (source) và đích (destination), như được hiển thị trong screenshot sau.\nNgoài ra, bạn có thể sử dụng Redshift Query Editor v2 để xác minh rằng dữ liệu của bạn đã được populate thành công. Một truy vấn đơn giản như SELECT * FROM customer; sẽ trả về dữ liệu đã được đồng bộ từ Aurora PostgreSQL database của bạn, như được hiển thị trong screenshot sau. Thiết lập Amazon Bedrock knowledge base với structured data Bước cuối cùng là tạo một Amazon Bedrock knowledge base, cho phép truy vấn dữ liệu bằng natural language.\nTạo Amazon Bedrock knowledge base Tạo một Amazon Bedrock knowledge base mới với tùy chọn structured data. Để biết hướng dẫn, xem Build a knowledge base by connecting to a structured data store. Sau đó, bạn phải đồng bộ query engine để cho phép truy cập dữ liệu.\nCấu hình quyền truy cập dữ liệu Trước khi quá trình đồng bộ thành công, bạn cần cấp các quyền thích hợp cho Amazon Bedrock Knowledge Bases AWS Identity and Access Management (IAM) role. Điều này bao gồm việc thực hiện các lệnh GRANT SELECT cho từng bảng trong Redshift database của bạn.\nChạy lệnh sau trong Redshift Query Editor v2 cho mỗi bảng: GRANT SELECT ON \u0026lt;table_name\u0026gt; TO \u0026ldquo;IAMR:\u0026rdquo;; Ví dụ: GRANT SELECT ON customer TO \u0026ldquo;IAMR:AmazonBedrockExecutionRoleForKnowledgeBase_ej0f0\u0026rdquo;;\nĐối với môi trường production, việc tích hợp identity của end-user vào luồng truy cập dữ liệu yêu cầu identity federation. Tham khảo tài liệu AWS về structured database access cho role-based access model. Đối với federating identities từ web clients, có thể cần Amazon Cognito hoặc SAML federation với AWS Security Token Service (AWS STS) tùy thuộc vào kiến trúc của bạn.\nXác minh thiết lập Sau khi hoàn tất cấu hình, knowledge base của bạn sẽ hiển thị các thông tin sau: Trạng thái là Available\nQuery engine đã được đồng bộ thành công với Amazon Redshift\nTrạng thái COMPLETE cho quá trình đồng bộ database\nBạn giờ có thể bắt đầu truy vấn dữ liệu của mình bằng natural language.\nVí dụ về truy vấn bằng natural language Khi đã thiết lập xong Amazon Bedrock knowledge base, bạn có thể bắt đầu kiểm tra khả năng của nó bằng cách thực hiện các truy vấn bằng natural language trên dữ liệu có cấu trúc. Structured data trong Amazon Bedrock Knowledge Bases sẽ chuyển đổi các câu hỏi bằng tiếng Anh sang SQL và sử dụng các FMs để tạo phản hồi dễ đọc cho con người.\nBạn có thể kiểm tra Amazon Bedrock knowledge base bằng hai cách:\n● Amazon Bedrock console – Trên Amazon Bedrock console, chọn Knowledge Bases trong navigation pane, và chọn knowledge base đã được cấu hình. Mở tab Test để tương tác với dữ liệu của bạn.\n● AWS SDK hoặc API – Sử dụng AWS SDK (ví dụ: Boto3 của Python) hoặc gọi trực tiếp RetrieveAndGenerate API để gửi truy vấn theo lập trình.\nTrong phần này, chúng tôi minh họa trải nghiệm trên console. Trên Amazon Bedrock console, bạn có thể tương tác với knowledge base theo hai chế độ:\n● Generate SQL queries – Tùy chọn này hiển thị câu lệnh SQL thô được tạo ra từ câu hỏi bằng natural language của bạn. ● Retrieval and response generation – Cung cấp phản hồi bằng natural language sử dụng một LLM. Bảng sau đây chứa một số ví dụ về các truy vấn và câu lệnh SQL tương ứng cùng với kết quả phản hồi được tạo bởi model. Truy vấn Natural Language Generate SQL Output Kết quả phản hồi Model Chúng ta có bao nhiêu khách hàng? SELECT COUNT(DISTINCT customer_id) AS num_customers FROM public.customer; We currently have 11 unique customers. Amazon Nova Lite Những khách hàng nào đã mua nhiều sản phẩm nhất? SELECT c.\u0026ldquo;customer_name\u0026rdquo;, COUNT(o.\u0026ldquo;product_id\u0026rdquo;) AS \u0026ldquo;total_products_purchased\u0026rdquo; FROM public.customer c INNER JOIN public.orders o ON c.\u0026ldquo;customer_id\u0026rdquo; = o.\u0026ldquo;customer_id\u0026rdquo; GROUP BY c.\u0026ldquo;customer_name\u0026rdquo; ORDER BY \u0026ldquo;total_products_purchased\u0026rdquo; DESC; Based on the data, the customers who have purchased the most products are Charlie Davis, Alice Brown, and John Doe, each having purchased 14 products. Following closely are Jane Smith, Grace Lee, and Bob Johnson, who have each purchased 13 products. Henry Taylor, Frank Miller, and Eva Wilson have each purchased 12 products, while Ivy Anderson has purchased 11 products. Amazon Nova Lite Những khách hàng nào đã mua nhiều hơn một sản phẩm đắt nhất? SELECT c.customer_name FROM public.customer c INNER JOIN public.orders o ON c.customer_id = o.customer_id INNER JOIN public.product p ON o.product_id = p.product_id WHERE p.price = (SELECT MAX(price) FROM public.product) GROUP BY c.customer_name HAVING COUNT(DISTINCT o.order_id); The customers who have purchased more than one number of the most expensive product are Grace Lee, Jane Smith, Alice Brown, and Eva Wilson. Amazon Nova Micro ● Retrieval and response generation – Cung cấp phản hồi bằng natural language sử dụng một LLM. Dọn dẹp Khi bạn đã sử dụng xong giải pháp này, hãy dọn dẹp các resources mà bạn đã tạo để tránh các chi phí phát sinh liên tục.\nKết luận Trong bài viết này, chúng tôi đã trình bày cách cho phép truy vấn bằng natural language trên dữ liệu Aurora PostgreSQL sử dụng Amazon Bedrock Knowledge Bases thông qua zero-ETL integration với Amazon Redshift. Chúng tôi đã hướng dẫn cách thiết lập database, cấu hình zero-ETL integration, và thiết lập kết nối knowledge base để truy cập dữ liệu một cách liền mạch. Mặc dù giải pháp này cung cấp một cách hiệu quả để tương tác với dữ liệu bằng natural language, bạn nên xem xét các chi phí lưu trữ bổ sung trong Amazon Redshift khi triển khai kiến trúc này cho trường hợp sử dụng của mình.\nHãy thử nghiệm giải pháp này và chia sẻ phản hồi của bạn trong phần comments.\nVề tác giả Girish B là Senior Solutions Architect tại AWS India Pvt Ltd, có trụ sở tại Bengaluru. Girish làm việc với nhiều khách hàng ISV để thiết kế và kiến trúc các giải pháp sáng tạo trên AWS.\nDani Mitchell là Generative AI Specialist Solutions Architect tại AWS. Cô tập trung vào việc giúp các doanh nghiệp trên toàn thế giới tăng tốc hành trình Generative AI của họ với Amazon Bedrock.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMở rộng quy mô các trường hợp sử dụng Generative AI – Phần 1: Kiến trúc đa thuê (multi-tenant) kiểu hub and spoke sử dụng AWS Transit Gateway Generative AI tiếp tục định hình cách các doanh nghiệp tiếp cận đổi mới và giải quyết vấn đề. Khách hàng đang dịch chuyển từ giai đoạn thử nghiệm sang mở rộng các use case generative AI trong tổ chức, với ngày càng nhiều doanh nghiệp tích hợp hoàn toàn các công nghệ này vào quy trình cốt lõi. Sự tiến hóa này trải dài qua các dòng kinh doanh (LOBs), các đội nhóm, và các nhà cung cấp phần mềm dạng dịch vụ (SaaS). Mặc dù nhiều khách hàng AWS thường bắt đầu bằng một tài khoản AWS đơn để chạy các proof-of-concept generative AI, việc tăng cường áp dụng và chuyển lên môi trường production đã dẫn đến những thách thức mới. Các thách thức này bao gồm quản lý và mở rộng triển khai hiệu quả, cũng như trừu tượng hóa và tái sử dụng các vấn đề chung như đa tenancy, cách ly (isolation), xác thực (authentication), ủy quyền (authorization), mạng an toàn (secure networking), giới hạn tốc độ (rate limiting) và caching. Để giải quyết những thách thức này một cách hiệu quả, kiến trúc đa tài khoản (multi-account) chứng tỏ có lợi, đặc biệt cho các nhà cung cấp SaaS phục vụ nhiều khách hàng doanh nghiệp, các tập đoàn lớn với các đơn vị riêng biệt, và các tổ chức có yêu cầu tuân thủ nghiêm ngặt. Cách tiếp cận đa tài khoản này giúp duy trì một hệ thống được kiến trúc tốt (well-architected) bằng cách cung cấp tổ chức tốt hơn, bảo mật và khả năng mở rộng cao hơn trong môi trường AWS của bạn. Nó cũng cho phép bạn quản lý các vấn đề chung này hiệu quả hơn khi bạn mở rộng các triển khai generative AI của mình. Trong loạt bài hai phần này, chúng tôi thảo luận mô hình kiến trúc hub và spoke để xây dựng kiến trúc đa-tenant và đa tài khoản. Mẫu này hỗ trợ trừu tượng hóa các dịch vụ dùng chung giữa các use case và các đội nhóm, giúp tạo ra hệ thống generative AI an toàn, có khả năng mở rộng và đáng tin cậy. Ở Phần 1, chúng tôi giới thiệu một hub tập trung cho các trừu tượng dịch vụ generative AI và các spoke dành riêng cho từng tenant, sử dụng AWS Transit Gateway để kết nối giữa các tài khoản. Tài khoản hub đóng vai trò là điểm vào cho yêu cầu người dùng cuối, tập trung các chức năng dùng chung như xác thực, ủy quyền, truy cập mô hình và quyết định định tuyến. Cách tiếp cận này giảm bớt nhu cầu triển khai các chức năng này riêng rẽ trong từng tài khoản spoke. Khi có thể, chúng tôi sử dụng các điểm cuối VPC (VPC endpoints) để truy cập các dịch vụ AWS. Trong Phần 2, chúng tôi thảo luận một biến thể kiến trúc này sử dụng AWS PrivateLink để chia sẻ an toàn endpoint tập trung trong tài khoản hub cho các đội trong tổ chức hoặc với đối tác bên ngoài. Trọng tâm trong cả hai bài là tập trung hóa xác thực, ủy quyền, truy cập mô hình và mạng an toàn đa tài khoản để onboarding và mở rộng use case generative AI với Amazon Bedrock. Chúng tôi không thảo luận các khả năng hệ thống khác như prompt catalog, prompt caching, versioning, đăng ký mô hình (model registry) và chi phí. Tuy nhiên, những khả năng đó có thể là phần mở rộng của kiến trúc này.\nSolution overview Giải pháp của chúng tôi thực hiện mẫu hub và spoke cung cấp hệ thống an toàn, có khả năng mở rộng để quản lý các triển khai generative AI trên nhiều tài khoản. Về cốt lõi, kiến trúc bao gồm một tài khoản hub tập trung làm điểm vào cho các yêu cầu, bổ sung với các tài khoản spoke chứa các tài nguyên dành riêng cho từng tenant. Sơ đồ sau minh họa kiến trúc này: Tài khoản hub đóng vai trò là tài khoản trung tâm, cung cấp các dịch vụ chung cho nhiều tenant và đóng vai trò là entry point cho các yêu cầu từ người dùng cuối. Nó tập trung các chức năng dùng chung như authentication, authorization, và routing decisions, giúp loại bỏ nhu cầu phải triển khai riêng các chức năng này cho từng tenant. Tài khoản hub được vận hành và bảo trì bởi core engineering team.\nCơ sở hạ tầng của hub bao gồm public và private VPCs, một internet-facing Application Load Balancer (ALB), Amazon Cognito để thực hiện authentication, và các VPC endpoints cần thiết cho các dịch vụ của AWS.\nCác tài khoản spoke chứa các tài nguyên dành riêng cho từng tenant, chẳng hạn như AWS Identity and Access Management (IAM) role permissions và các tài nguyên Amazon Bedrock. Các tài khoản spoke có thể được quản lý bởi core engineering team hoặc bởi chính tenant, tùy thuộc vào nhu cầu của tổ chức.\nMỗi tài khoản spoke duy trì private VPC riêng, VPC interface endpoints cho Amazon Bedrock, các IAM roles và permissions cụ thể, cùng các account-level controls. Các thành phần này được kết nối thông qua Transit Gateway, giúp cung cấp secure cross-account networking và quản lý luồng lưu lượng giữa các hub và spoke VPCs. Luồng yêu cầu qua hệ thống (như được mô tả trong sơ đồ kiến trúc trước đó) bao gồm các bước sau: Một người dùng (đại diện cho Tenant 1, 2, hoặc N) truy cập client application.\nClient application trong public subnet của tài khoản hub xác thực người dùng và nhận ID/JWT token. Trong ví dụ này, chúng ta sử dụng Amazon Cognito user pool làm identity provider (IdP).\nClient application sử dụng các custom attributes trong JWT token để xác định tuyến tương ứng trong ALB. ALB, dựa trên context path, định tuyến yêu cầu đến tenant’s AWS Lambda function target group.\nTenant-specific Lambda function trong private subnet của tài khoản hub được gọi thực thi.\nHàm này assumes a cross-account role trong tài khoản của tenant. Hàm gọi Amazon Bedrock trong tài khoản spoke bằng cách tham chiếu regional DNS name của Amazon Bedrock VPCE. Mô hình được gọi thực thi và kết quả được gửi lại cho người dùng.\nKiến trúc này đảm bảo rằng các yêu cầu đều đi qua một central entry point trong khi vẫn duy trì được tenant isolation. Bằng cách gọi Amazon Bedrock trong tài khoản spoke, mỗi yêu cầu sẽ kế thừa account’s limits, access control, cost assignments, service control policies (SCPs), và các account-level controls khác. Mẫu mã nguồn (sample code) cho giải pháp này được chia thành hai phần:\nPhần đầu tiên minh họa giải pháp cho một single hub and spoke account.\nPhần thứ hai mở rộng giải pháp bằng cách triển khai thêm một spoke account khác.\nHướng dẫn chi tiết cho từng bước được cung cấp trong tệp repository README. Trong các phần tiếp theo, chúng tôi sẽ cung cấp outline cho các bước triển khai.\nPrerequisites Chúng tôi giả định rằng bạn đã quen thuộc với các kiến thức cơ bản về AWS networking, bao gồm Amazon Virtual Private Cloud (Amazon VPC) và các VPC constructs như route tables và các VPC interconnectivity options. Chúng tôi cũng giả định rằng bạn hiểu về multi-tenant architectures và các nguyên tắc cốt lõi của việc phục vụ nhiều tenant trên một shared infrastructure trong khi vẫn duy trì isolation.\nĐể triển khai giải pháp này, bạn cần có các prerequisites sau: Hub và spoke accounts (bắt buộc):\nHai tài khoản AWS: một hub account và một spoke account\nQuyền truy cập vào amazon.titan-text-lite-v1 model trong spoke account\nAdditional spoke account (tùy chọn): Một tài khoản AWS thứ ba (spoke account dành cho tenant thứ hai)\nQuyền truy cập vào anthropic.claude-3-haiku-20240307-v1:0 model trong second spoke account\nCác yếu tố thiết kế (Design considerations) Việc triển khai kiến trúc này bao gồm nhiều lựa chọn thiết kế quan trọng ảnh hưởng đến cách giải pháp vận hành, khả năng mở rộng và khả năng bảo trì. Trong phần này, chúng ta xem xét các yếu tố thiết kế này trên các thành phần khác nhau, giải thích lý do đằng sau mỗi lựa chọn và các phương án thay thế tiềm năng khi có thể.\nLambda functions Trong thiết kế của chúng tôi, ALB target group được cấu hình là Lambda functions chạy trong hub account thay vì spoke account. Cách tiếp cận này cho phép centralized management của business logic, cũng như centralized logging và monitoring. Khi kiến trúc phát triển để bao gồm các chức năng dùng chung như prompt caching, semantic routing, hoặc sử dụng large language model (LLM) proxies (các middleware services cung cấp quyền truy cập thống nhất vào nhiều models trong khi xử lý rate limiting và request routing, như được thảo luận trong Part 2), việc triển khai các tính năng này trong hub account sẽ đảm bảo consistency giữa các tenant. Chúng tôi chọn Lambda functions để triển khai token validation và routing logic, tuy nhiên bạn cũng có thể sử dụng các tùy chọn compute khác như Amazon Elastic Container Service (Amazon ECS) hoặc Amazon Elastic Kubernetes Service (Amazon EKS) tùy thuộc vào preferences của tổ chức bạn.\nChúng tôi sử dụng 1-to-1 mapping giữa Lambda functions và từng tenant. Mặc dù logic hiện tại trong mỗi function là tương tự nhau, việc có một dedicated function cho từng tenant có thể giúp giảm thiểu các vấn đề noisy neighbor và hỗ trợ các cấu hình riêng biệt cho từng tenant tier, chẳng hạn như memory và concurrency.\nVPC endpoints Trong giải pháp này, chúng tôi sử dụng các dedicated Amazon Bedrock runtime VPC endpoints trong các spoke accounts. Việc sử dụng dedicated VPC endpoints cho từng spoke account phù hợp với các tổ chức mà operators của spoke account chịu trách nhiệm quản lý các tính năng tenant, chẳng hạn như cho phép truy cập models, thiết lập knowledge bases, và guardrails. Tùy thuộc vào policies của tổ chức, có thể triển khai một biến thể khác của kiến trúc này bằng cách sử dụng centralized Amazon Bedrock runtime VPC trong hub account (như được mô tả trong Part 2). Centralized VPC endpoints phù hợp với các tổ chức mà central engineering team quản lý các tính năng cho các tenants.\nCác yếu tố khác như costs, access control, và endpoint quotas cần được xem xét khi lựa chọn giữa centralized hoặc dedicated approach cho vị trí của Amazon Bedrock VPC endpoints. VPC endpoint policies với centralized approach có thể gặp phải giới hạn 20,480-character limit khi số lượng tenants tăng lên. Có hourly fees cho VPC endpoints và transit gateway attachments được provisioned bất kể có được sử dụng hay không. Nếu VPC endpoints được provisioned trong spoke accounts, mỗi tenant sẽ chịu thêm hourly fees.\nClient application Vì mục đích trình diễn, client application trong giải pháp này được deployed trong public subnet của hub VPC. Ứng dụng có thể được deployed trong một account bên ngoài cả hub và spoke VPCs, hoặc deployed at the edge như một single-page application (SPA) bằng cách sử dụng Amazon CloudFront và Amazon Simple Storage Service (Amazon S3).\nTenancy Các enterprises sử dụng nhiều tenancy models khác nhau khi scaling generative AI, mỗi loại có advantages và disadvantages riêng. Giải pháp của chúng tôi triển khai silo model, gán mỗi tenant cho một dedicated spoke account. Đối với các organizations nhỏ hơn, có ít tenants và yêu cầu isolation không quá nghiêm ngặt, một cách tiếp cận thay thế là pooled model (nhiều tenants trong một spoke account) có thể phù hợp hơn — trừ khi họ có kế hoạch scale significantly trong tương lai hoặc có yêu cầu tuân thủ cụ thể (compliance requirements). Để biết thêm thông tin về multi-tenancy design, xem Let’s Architect! Designing architectures for multi-tenancy. Cell-based architectures cho multi-tenant applications có thể mang lại lợi ích như fault isolation và scaling. Xem Reducing the Scope of Impact with Cell-Based Architecture để biết thêm chi tiết.\nFrontend gateway Trong giải pháp này, chúng tôi chọn ALB làm entry point cho các requests. ALB mang lại nhiều lợi thế cho generative AI use case của chúng tôi:\nLong-running connections – ALB hỗ trợ các kết nối lên đến 4,000 seconds, có lợi cho các phản hồi LLM có thể mất hơn 30 seconds để hoàn thành.\nScalability – ALB có thể xử lý khối lượng lớn concurrent connections, phù hợp cho các enterprise-scale deployments.\nIntegration with AWS WAF – ALB tích hợp liền mạch với AWS WAF, cung cấp enhanced security và protection chống lại các common web exploits.\nAmazon API Gateway là một tùy chọn thay thế khi cần API versioning, usage plans, hoặc các granular API management capabilities, và khi message sizes và response times phù hợp với các quotas của nó. AWS AppSync là một tùy chọn khác phù hợp khi muốn expose LLMs thông qua GraphQL interface. Hãy chọn gateway phù hợp nhất với customers của bạn:\nALB xử lý hiệu quả các high-volume, long-running connections.\nAPI Gateway cung cấp comprehensive REST API management.\nAWS AppSync mang lại real-time GraphQL capabilities.\nĐánh giá từng tùy chọn dựa trên yêu cầu về response time, API needs, scale demands, và specific use case của ứng dụng bạn. Mặc dù bài viết này trình diễn kết nối bằng HTTP để đơn giản hóa, nhưng điều này không được khuyến nghị cho production. Các production deployments luôn phải triển khai HTTPS với proper SSL/TLS certificates để duy trì secure communication.\nIP addressing AWS CloudFormation template để deploy solution resources sử dụng example CIDRs. Khi deploy kiến trúc này trong second spoke account, hãy sử dụng các unique IP addresses không bị overlap với các môi trường hiện có. Transit Gateway hoạt động ở Layer 3 và yêu cầu các distinct IP spaces để route traffic giữa các VPCs.\nDeploy a hub and spoke account Trong phần này, chúng tôi thiết lập môi trường AWS Command Line Interface (AWS CLI) cục bộ để deploy giải pháp này trong hai AWS accounts. Hướng dẫn chi tiết được cung cấp trong repository README. Deploy một CloudFormation stack trong hub account, và một stack khác trong spoke account.\nConfigure connectivity giữa hub và spoke VPCs bằng Transit Gateway attachments.\nTạo một Amazon Cognito user với giá trị tenant1 cho custom user attribute có tên tenant_id.\nTạo một item trong Amazon DynamoDB table để map tenant ID với model access và routing information cụ thể cho tenant, trong ví dụ của chúng tôi là tenant1. Xác thực kết nối (Validate connectivity) Trong phần này, chúng ta xác thực connectivity từ một test application trong hub account đến Amazon Bedrock model trong spoke account. Chúng ta thực hiện điều này bằng cách gửi một curl request từ một EC2 instance (đại diện cho client application của chúng ta) đến ALB. Cả EC2 instance và ALB đều nằm trong public subnet của hub account. Request và response sau đó được định tuyến thông qua Transit Gateway attachments giữa hub và spoke VPCs. Ảnh chụp màn hình sau đây cho thấy quá trình thực thi một utility script trên local workstation của bạn, script này authenticates một người dùng và exports các necessary variables. Những variables này sẽ được sử dụng để construct curl request trên EC2 instance.\nẢnh chụp màn hình tiếp theo cho thấy curl request đang được thực thi từ EC2 instance đến ALB. Response xác nhận rằng request đã được xử lý thành công và được phục vụ bởi amazon.titan-text-lite-v1 model, đây là model được mapped đến người dùng này (tenant1). Model này được hosted trong spoke account. Deploy a second spoke account Trong phần này, chúng ta mở rộng deployment để bao gồm một second spoke account cho một additional tenant. Chúng ta xác thực multi-tenant connectivity bằng cách gửi một curl request khác từ cùng một EC2 instance đến ALB trong hub account. Detailed instructions được cung cấp trong repository README. Ảnh chụp màn hình sau cho thấy response cho request này, chứng minh rằng hệ thống xác định và định tuyến requests dựa trên thông tin tenant một cách chính xác. Trong trường hợp này, giá trị tenant_id attribute của người dùng là tenant2, và request được định tuyến thành công đến anthropic.claude-3-haiku-20240307-v1:0 model, model này được mapped đến tenant2 trong second spoke account.\nClean up Để clean up các resources của bạn, hãy hoàn thành các bước sau: Nếu bạn đã tạo các optional resources cho second spoke account, hãy xóa chúng: Change the directory đến genai-secure-patterns/hub-spoke-transit-gateway/scripts/optional\nRun the cleanup script ./cleanupOptionalStack.sh\nClean up main stack: Change the directory đến genai-secure-patterns/hub-spoke-transit-gateway/scripts/\nRun the cleanup script ./cleanup.sh\nConclusion Khi các tổ chức ngày càng adopt và scale các generative AI use cases trên nhiều teams và LOBs (lines of business) khác nhau, nhu cầu về secure, scalable, và reliable multi-tenant architectures ngày càng tăng. Loạt bài gồm hai phần này đáp ứng nhu cầu đó bằng cách cung cấp hướng dẫn về cách implement hub and spoke architecture pattern. Bằng cách adopting những well-architected practices như vậy ngay từ đầu, bạn có thể xây dựng các scalable và robust solutions giúp khai thác toàn bộ tiềm năng của generative AI trong tổ chức của bạn. Trong bài viết này, chúng ta đã trình bày cách set up một centralized hub account lưu trữ các shared services như authentication, authorization, và networking bằng Transit Gateway. Chúng ta cũng đã minh họa cách configure các spoke accounts để lưu trữ các tenant-specific resources như Amazon Bedrock. Hãy thử các code samples được cung cấp để xem architecture này hoạt động như thế nào trong thực tế. Part 2 sẽ khám phá một cách implementation thay thế bằng cách sử dụng PrivateLink để interconnect các VPCs trong hub và spoke accounts.\nAbout the Authors Nikhil Penmetsa là Senior Solutions Architect tại AWS. Anh giúp các tổ chức hiểu rõ best practices liên quan đến các advanced cloud-based solutions. Anh đam mê việc diving deep cùng khách hàng để tạo ra các solutions vừa cost-effective, secure, và performant. Khi không ở văn phòng, bạn thường thấy anh putting in miles trên xe đạp đường dài hoặc hitting the open road trên chiếc motorbike của mình.\nRam Vittal là Principal ML Solutions Architect tại AWS. Ông có hơn 3 decades of experience trong việc architecting và building distributed, hybrid, and cloud applications. Ông đam mê việc xây dựng các secure và scalable AI/ML và big data solutions để giúp enterprise customers trong hành trình cloud adoption và optimization nhằm cải thiện business outcomes của họ. Trong thời gian rảnh, ông rides his motorcycle và walks with his 3-year-old Sheepadoodle!\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nXác thực event payload với Powertools for AWS Lambda (TypeScript) Trong bài viết này, hãy tìm hiểu cách Powertools for AWS Lambda (TypeScript) với Parser utility mới có thể giúp bạn xác thực (validate) payloads một cách dễ dàng và làm cho Lambda function của bạn trở nên chống chịu tốt hơn hơn. Việc validate input payloads là một khía cạnh quan trọng trong việc xây dựng các ứng dụng secure và reliable. Điều này đảm bảo rằng dữ liệu mà một ứng dụng nhận được có thể xử lý trơn tru các unexpected hoặc malicious inputs và ngăn chặn harmful downstream processing. Khi viết AWS Lambda functions, các developer cần validate và verify payload, đồng thời đảm bảo rằng các fields và values cụ thể là chính xác và an toàn để xử lý.\nPowertools for AWS Lambda là một developer toolkit có sẵn cho Python, NodeJS/TypeScript, Java và .NET. Nó giúp triển khai serverless best practices và tăng tốc độ phát triển (developer velocity). Powertools for AWS Lambda (TypeScript) hiện đang giới thiệu một Parser utility mới để giúp các developer dễ dàng hơn trong việc triển khai validation trong Lambda functions của họ.\nTại sao việc payload validation lại quan trọng Validating payloads có thể giúp Lambda functions của bạn trở nên resilient hơn. Payloads kết hợp cả technical và business information cũng có thể gây khó khăn trong việc validate. Điều này đòi hỏi phải viết validation logic bên trong Lambda function code của bạn. Việc này có thể dao động từ một vài if-statements để kiểm tra payload values, cho đến một chuỗi các validation steps phức tạp dựa trên custom business logic. Bạn có thể cần phải tách riêng việc validation của technical information trong payload như AWS Region, accountId, event source, và business information bên trong event như productId và payment details.\nViệc hiểu rõ structure và values của event object, cũng như cách extract relevant information, có thể rất thách thức. Ví dụ, một Amazon SQS event có một body field với string value, có thể là một JSON document. Amazon EventBridge có một object trong detail field mà bạn có thể đọc trực tiếp mà không cần transformation thêm. Bạn có thể cần phải decompress, decode, transform, và validate payload bên trong một specific field. Việc hiểu rõ nhiều transformation layers có thể trở nên phức tạp, đặc biệt nếu event object của bạn là kết quả của nhiều service invocations.\nSử dụng Powertools for AWS Lambda (TypeScript) Parser Utility Powertools for AWS Lambda (TypeScript) là một modular library. Bạn có thể cài đặt có chọn lọc các features như Logger, Tracer, Metrics, Batch Processing, Idempotency, và nhiều hơn nữa. Bạn có thể sử dụng Powertools for AWS Lambda trong cả TypeScript và JavaScript code bases. Parser utility mới này giúp đơn giản hóa việc validation và sử dụng validation library phổ biến là Zod. Bạn có thể sử dụng parser như một method decorator, với middyjs middleware, hoặc manually trong tất cả các Lambda provided NodeJS runtimes.\nĐể sử dụng utility, hãy install Powertools parser utility và Zod (\u0026lt;v3.x) bằng NPM hoặc bất kỳ package manager nào mà bạn chọn: npm install @aws-lambda-powertools/parser zod@~3 Bạn có thể định nghĩa schema của mình bằng cách sử dụng Zod. Dưới đây là ví dụ về một simple order schema để validate events: import { z } from \u0026lsquo;zod\u0026rsquo;; const orderSchema = z.object({ id: z.number().positive(), description: z.string(), items: z.array( z.object({ id: z.number().positive(), quantity: z.number(), description: z.string(), }) ), }); export { orderSchema }; Schema sau đây định nghĩa id, description, và một list of items. Bạn có thể chỉ định value types từ simple numeric, thu hẹp lại thành positive hoặc literal, hoặc phức tạp hơn như union, array, hoặc thậm chí other schema. Zod cung cấp một danh sách phong phú các value types mà bạn có thể sử dụng.\nThêm parser decorator vào handler function của bạn, đặt schema parameter, và sử dụng schema này để parse event object. import type {Context} from \u0026lsquo;aws-lambda\u0026rsquo;; import type {LambdaInterface} from \u0026lsquo;@aws-lambda-powertools/commons/types\u0026rsquo;; import {parser} from \u0026lsquo;@aws-lambda-powertools/parser\u0026rsquo;; import {z} from \u0026lsquo;zod\u0026rsquo;; import {Logger} from \u0026lsquo;@aws-lambda-powertools/logger\u0026rsquo;;\nconst logger = new Logger();\nconst orderSchema = z.object({ id: z.number().positive(),\ndescription: z.string(),\nitems: z.array( z.object({ id: z.number().positive(), quantity: z.number(), description: z.string(), }) ), });\ntype Order = z.infer;\nclass Lambda implements LambdaInterface { @parser({schema: orderSchema})\npublic async handler(event: Order, _context: Context): Promise { // event is now typed as Order for (const item of event.items) { logger.info(\u0026lsquo;Processing item\u0026rsquo;, {item}); // process order item from the event } } }\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction); Lưu ý rằng z.infer giúp extract Order type từ schema, điều này cải thiện development experience với autocomplete khi sử dụng TypeScript. Zod sẽ parse entire object, bao gồm cả nested fields, và báo cáo tất cả errors kết hợp, thay vì chỉ trả về error đầu tiên.\nSử dụng built-in schema cho AWS services Một trường hợp phổ biến hơn là cần validate events từ các AWS Services kích hoạt Lambda functions, bao gồm Amazon SQS, Amazon EventBridge, và nhiều dịch vụ khác. Để việc này dễ dàng hơn, Powertools bao gồm các pre-built schema cho các AWS events mà bạn có thể sử dụng.\nĐể parse một Amazon EventBridge event đến, hãy thiết lập built-in schema trong cấu hình parser của bạn:\nimport {LambdaInterface} from \u0026lsquo;@aws-lambda-powertools/commons/types\u0026rsquo;; import {Context} from \u0026lsquo;aws-lambda\u0026rsquo;; import {parser} from \u0026lsquo;@aws-lambda-powertools/parser\u0026rsquo;; import {EventBridgeSchema} from \u0026lsquo;@aws-lambda-powertools/parser/schemas\u0026rsquo;; import type {EventBridgeEvent} from \u0026lsquo;@aws-lambda-powertools/parser/types\u0026rsquo;;\nclass Lambda implements LambdaInterface {\n@parser({schema: EventBridgeSchema})\npublic async handler(event: EventBridgeEvent, _context: Context): Promise { // event is parsed but the detail field is not specified\n} }\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\nEvent object được parsed và validated trong runtime, và TypeScript type EventBridgeEvent giúp bạn hiểu cấu trúc và truy cập các fields trong quá trình phát triển. Trong ví dụ này, bạn chỉ parse EventBridge event object, vì vậy detail field có thể là một arbitrary object. Bạn cũng có thể extend built-in EventBridge schema và override detail field bằng custom orderSchema của bạn:\nimport {LambdaInterface} from \u0026lsquo;@aws-lambda-powertools/commons/types\u0026rsquo;; import {Context} from \u0026lsquo;aws-lambda\u0026rsquo;; import {parser} from \u0026lsquo;@aws-lambda-powertools/parser\u0026rsquo;; import {EventBridgeSchema} from \u0026lsquo;@aws-lambda-powertools/parser/schemas\u0026rsquo;; import {z} from \u0026lsquo;zod\u0026rsquo;;\nconst orderSchema = z.object({\nid: z.number().positive(),\ndescription: z.string(),\nitems: z.array( z.object({ id: z.number().positive(), quantity: z.number(), description: z.string(), }), ), });\nconst eventBridgeOrderSchema = EventBridgeSchema.extend({ detail: orderSchema,});\ntype EventBridgeOrder = z.infer;\nclass Lambda implements LambdaInterface {\n@parser({schema: eventBridgeOrderSchema}) public async handler(event: EventBridgeOrder, _context: Context): Promise { // event.detail is now parsed as orderSchema\n} }\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\nParser sẽ validate toàn bộ cấu trúc của EventBridge event, bao gồm custom business object. Sử dụng .extend hoặc các Zod schema functions khác để thay đổi bất kỳ field nào của built-in schema và customize payload validation.\nSử dụng envelopes với custom schema Trong một số trường hợp, bạn chỉ cần phần custom của payload, ví dụ detail field của EventBridge event hoặc body của SQS records. Việc này yêu cầu bạn parse event schema thủ công, extract field cần thiết, rồi parse lại với custom schema. Điều này phức tạp vì bạn phải biết chính xác payload field nào cần xử lý và cách transform \u0026amp; parse nó.\nPowertools Parser utility giúp giải quyết vấn đề này bằng Envelopes.Envelopes là các schema objects có sẵn logic để extract custom payloads.\nDưới đây là ví dụ về EventBridgeEnvelope và cách hoạt động của nó: import {LambdaInterface} from \u0026lsquo;@aws-lambda-powertools/commons/types\u0026rsquo;; import {Context} from \u0026lsquo;aws-lambda\u0026rsquo;; import {parser} from \u0026lsquo;@aws-lambda-powertools/parser\u0026rsquo;; import {EventBridgeEnvelope} from \u0026lsquo;@aws-lambda-powertools/parser/envelopes\u0026rsquo;; import {z} from \u0026lsquo;zod\u0026rsquo;;\nconst orderSchema = z.object({\nid: z.number().positive(), description: z.string(),\nitems: z.array( z.object({ id: z.number().positive(), quantity: z.number(), description: z.string(), }), ), });\ntype Order = z.infer;\nclass Lambda implements LambdaInterface {\n@parser({schema: orderSchema, envelope: EventBridgeEnvelope}) public async handler(event: Order, _context: Context): Promise { // event is now typed as Order inferred from the orderSchema\n} }\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\nBằng cách thiết lập schema và envelope, parser utility sẽ biết cách kết hợp cả hai tham số, extract và validate custom payload từ event. Powertools Parser transform event object theo schema definition, cho phép bạn tập trung vào phần business-critical trong handler function.\nSafe parsing Nếu object không khớp với Zod schema được cung cấp, theo mặc định, parser sẽ ném ra ParserError.Nếu bạn cần kiểm soát validation errors và muốn triển khai custom error handling, hãy sử dụng tùy chọn safeParse.\nDưới đây là ví dụ về cách capture failed validations như một metric trong handler function của bạn: import {Logger} from \u0026ldquo;@aws-lambda-powertools/logger\u0026rdquo;; import {LambdaInterface} from \u0026ldquo;@aws-lambda-powertools/commons/types\u0026rdquo;; import {parser} from \u0026ldquo;@aws-lambda-powertools/parser\u0026rdquo;; import {orderSchema} from \u0026ldquo;../app/schema\u0026rdquo;;import {z} from \u0026ldquo;zod\u0026rdquo;; import {EventBridgeEnvelope} from \u0026ldquo;@aws-lambda-powertools/parser/envelopes\u0026rdquo;; import {Metrics, MetricUnit} from \u0026ldquo;@aws-lambda-powertools/metrics\u0026rdquo;; import {ParsedResult, EventBridgeEvent} from \u0026ldquo;@aws-lambda-powertools/parser/types\u0026rdquo;;\nconst logger = new Logger();\nconst metrics = new Metrics();\ntype Order = z.infer;\nclass Lambda implements LambdaInterface {\n@metrics.logMetrics() @parser({schema: orderSchema, envelope: EventBridgeEnvelope, safeParse: true}) public async handler(event: ParsedResult\u0026lt;EventBridgeEvent, Order\u0026gt;, _context: unknown): Promise\u0026lt;void\u0026gt; { if (!event.success) { // failed validation metrics.addMetric('InvalidPayload', MetricUnit.Count, 1); logger.error('Invalid payload', event.originalEvent); } else { // successful validation for (const item of event.data.items) { logger.info('Processing item', item); // event.data is typed as Order } } } }\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\nKhi đặt safeParse = true, parser sẽ không ném lỗi, mà sẽ trả về event object đã được sửa đổi với success flag và các fields error hoặc data tùy theo kết quả validation. Bạn có thể tạo custom error handling, ví dụ tăng metric InvalidPayload và truy cập originalEvent để ghi log lỗi. Với các validations thành công, bạn có thể truy cập data field và xử lý payload. Lưu ý rằng event object type bây giờ là ParsedResult, với EventBridgeEvent là input và Order là output type.\nCustom validations Đôi khi bạn có thể cần các business rules phức tạp hơn cho quá trình validation. Vì Parser built-in schemas là các Zod objects, bạn có thể customize validation bằng cách áp dụng .extend, .refine, .transform, và các Zod operators khác.\nDưới đây là ví dụ về các complex rules cho orderSchema: import {z} from \u0026lsquo;zod\u0026rsquo;;\nconst orderSchema = z.object({ id: z.number().positive(),\ndescription: z.string(),\nitems: z.array(z.object({ id: z.number().positive(), quantity: z.number(), description: z.string(),\n})).refine((items) =\u0026gt; items.length \u0026gt; 0, { message: \u0026lsquo;Order must have at least one item\u0026rsquo;,\n}), })\n.refine((order) =\u0026gt; order.id \u0026gt; 100 \u0026amp;\u0026amp; order.items.length \u0026gt; 100, { message: \u0026lsquo;All orders with more than 100 items must have an id greater than 100\u0026rsquo;, });\nSử dụng .refine trên items field để kiểm tra xem order có ít nhất một item hay không. Bạn cũng có thể kết hợp nhiều fields, ví dụ order.id và order.items.length, để tạo quy tắc cụ thể cho các orders có hơn 100 items. Lưu ý rằng .refine chạy trong bước validation, còn .transform sẽ được áp dụng sau khi validation hoàn tất. Điều này cho phép bạn thay đổi hình dạng dữ liệu để normalize output.\nConclusion Powertools for AWS Lambda (TypeScript) giới thiệu Parser utility mới giúp việc thêm validation vào Lambda functions trở nên dễ dàng hơn. Bằng cách dựa vào validation library Zod phổ biến, Powertools cung cấp một bộ built-in schemas phong phú cho các AWS service integrations như Amazon SQS, Amazon DynamoDB, Amazon EventBridge. Các developers có thể sử dụng các schemas này để validate event payloads và customize chúng theo nhu cầu business của mình.\nHãy truy cập documentation để tìm hiểu thêm và tham gia Powertools community Discord để kết nối với các serverless enthusiasts có cùng đam mê.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.3-event/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Summary Report: AI/ML/GenAI on AWS (AWS Cloud Mastery Series #1) Event Objectives Giới thiệu tổng quan hệ sinh thái AI/ML tại Việt Nam và tiềm năng ứng dụng trong doanh nghiệp Trình bày toàn bộ vòng đời Machine Learning trên Amazon SageMaker Hướng dẫn xây dựng và triển khai ứng dụng Generative AI với Amazon Bedrock Trang bị kỹ năng prompt engineering, RAG, Foundation Models và triển khai chatbot AI Speakers Key Highlights AI/ML Landscape \u0026amp; Community Connection Định hướng xu hướng AI/ML tại Việt Nam Ice-breaker kết nối học viên và kỹ sư Mở rộng network và trao đổi giải pháp thực tế AWS AI/ML Services Amazon SageMaker – Nền tảng ML toàn diện\nXử lý dữ liệu, labeling, training, tuning, deployment Lean MLOps management, model monitoring Live Demo: SageMaker Studio Generative AI with Amazon Bedrock Foundation Models: Claude, Llama, Titan Prompt Engineering: CoT, few-shot, context injection RAG Integration + Knowledge Bases Bedrock Agents \u0026amp; Guardrails Live Demo: Build AI chatbot Event Experience Buổi workshop mang lại góc nhìn thực tế về AI/ML và GenAI trên AWS.\nCân bằng giữa học thuật và thực hành giúp mình hiểu rõ quy trình từ training → deploy.\nPhần Bedrock ấn tượng nhất vì có thể tự tạo chatbot và áp dụng trực tiếp.\nWorkshop giúp mình tự tin hơn khi triển khai GenAI cho dự án thực tế.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.2-event/",
	"title": "Event 4",
	"tags": [],
	"description": "",
	"content": "Summary Report: ​DevOps on AWS (AWS Cloud Mastery Series #2) Event Objectives Hiểu sâu hơn về tư duy DevOps và văn hoá triển khai Nắm rõ mô hình Infrastructure as Code và cách ứng dụng Mở rộng kiến thức về dịch vụ container trên AWS Cải thiện khả năng quan sát hệ thống, giám sát và logging Speakers Truong Quang Trinh – Kỹ sư Nền tảng – AWS Community Builder tại TymeX Bao Huynh – AWS Community Builders Thinh Nguyen – AWS Community Builders Vi Tran – AWS Community Builders Long Huynh – AWS Community Builders Quy Pham – AWS Community Builders Nghiem Le – AWS Community Builders Key Highlights AWS CodeCommit Dịch vụ quản lý mã nguồn dựa trên Git chạy hoàn toàn trên AWS Hỗ trợ nhiều workflow: GitFlow, Trunk-Based và feature branch Phù hợp cho teamwork, code review và tích hợp CI/CD tự động AWS CodeBuild Build service do AWS quản lý—dùng để compile, test và đóng gói ứng dụng Cho phép tuỳ chỉnh buildspec để định nghĩa pipeline Tối ưu quy trình CI khi có thể chạy test tự động trong pipeline AWS CodeDeploy Tự động hoá quá trình triển khai lên EC2, Lambda hoặc môi trường On-premise Hỗ trợ nhiều chiến lược deploy: Blue/Green, Rolling, Canary Giảm thiểu downtime và hạn chế lỗi khi release AWS CodePipeline Công cụ điều phối CI/CD end-to-end (build → test → deploy) Tự động hoá release, hỗ trợ đa môi trường và rollback linh hoạt Thích hợp cho continuous delivery không cần thao tác thủ công AWS CloudFormation Quản lý hạ tầng bằng template (IaC) giúp tạo resource lặp lại, kiểm soát tốt hơn Có cơ chế rollback, drift detection để đảm bảo trạng thái đúng như cấu hình Tự động hoá cấp phát, giảm sai sót do thao tác tay AWS CDK (Cloud Development Kit) Viết hạ tầng bằng code (TypeScript/Python/JS) thay vì YAML/JSON Cung cấp construct template sẵn giúp triển khai nhanh hơn Biên dịch lại thành CloudFormation nên dùng trong production an toàn Container Services on AWS Giải thích cơ bản Docker và container hoá microservices Amazon ECR dùng lưu trữ image + quét bảo mật + retention policy ECS/EKS để chạy container scale lớn, tự động điều phối workload App Runner cho phép deploy ứng dụng container đơn giản không cần quản lý hạ tầng Monitoring \u0026amp; Observability CloudWatch: quản lý log, metric, alarm và dashboard AWS X-Ray dùng để trace request, phân tích hiệu năng từng service Tăng khả năng theo dõi hệ thống từ backend → frontend DevOps Best Practices \u0026amp; Case Studies Triển khai nhiều chiến lược release: feature flag, A/B test, canary deployment Khuyến khích tự động hoá test trong CI/CD Tìm hiểu quy trình xử lý sự cố và viết postmortem chuẩn Nêu case study thực tế từ startup đến doanh nghiệp lớn Event Experience Qua sự kiện DevOps on AWS, mình có cơ hội củng cố lại kiến thức về DevOps cũng như hiểu rõ hơn cách vận hành các "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/4.1-event/",
	"title": "Sư kiện 7",
	"tags": [],
	"description": "",
	"content": "Báo Cáo Tóm Tắt: AWS Well-Architected Security Pillar (AWS Cloud Mastery Series #3) Mục Tiêu Sự Kiện Tìm hiểu sâu hơn về các dịch vụ IAM, IAM Identity Center, SSO, SCP Học về CloudTrail, GuardDuty, Security Hub và tự động hóa bằng EventBridge Bảo vệ hạ tầng: phân tách VPC, vị trí tài nguyên public vs private Tìm hiểu về Bảo vệ Dữ liệu và Incident Response Diễn Giả Mendel Grabski (Long): Cựu Head of Security \u0026amp; DevOps – Cloud Security Solution Architect Tinh Truong: AWS Community Builder – Kỹ sư Nền tảng tại TymeX Những Điểm Nổi Bật Identity \u0026amp; Access Management Hiểu các khái niệm IAM cốt lõi: Users, Roles, Policies và lý do nên tránh long-term credentials. Khám phá IAM Identity Center (SSO) và Permission Sets. Nắm các thực hành bảo mật quan trọng: MFA, credential rotation, IAM Access Analyzer. Detection Hiểu CloudTrail cung cấp auditing đầy đủ trên multi-account. Tìm hiểu các dịch vụ phát hiện mối đe dọa: GuardDuty và Security Hub. Nắm logging ở nhiều lớp: VPC Flow Logs, ALB Logs, S3 Access Logs. Xây dựng cảnh báo và automation với EventBridge. Infrastructure Protection KMS: key policies, grants, rotation Mã hóa at-rest \u0026amp; in-transit: S3, EBS, RDS, DynamoDB Secrets Manager \u0026amp; Parameter Store — các mẫu xoay vòng secrets Phân loại dữ liệu và thiết lập access guardrails Incident Response Vòng đời IR trên AWS Xử lý khi IAM key bị lộ Kiểm tra S3 public exposure Phát hiện malware trên EC2 Snapshot, cô lập, thu thập bằng chứng Tự động phản hồi bằng Lambda/Step Functions Trải Nghiệm Sự Kiện Tham gia sự kiện AWS Well-Architected Security Pillar, mình không chỉ học thêm nhiều dịch vụ mới mà còn có cơ hội gặp gỡ các bạn từ nhiều trường đại học khác. Học thêm về các dịch vụ bảo mật, biết thêm về cách xử lý sự cố thực tế. Ngoài ra còn có cơ hội gặp chuyên gia nước ngoài đang làm việc tại AWS và lắng nghe chia sẻ kinh nghiệm của họ. Một Số Hình Ảnh Tại Sự Kiện Sự kiện giúp mình hiểu rõ hơn về bảo mật, có cơ hội tìm hiểu thêm về các sự cố và cách giải quyết. Đồng thời, mình cũng mong muốn tham gia CloudClub để có thêm nhiều trải nghiệm và kỷ niệm đẹp.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-dynamodb-s3/5.3.1-dynamodb/",
	"title": "Tạo DynamoDB",
	"tags": [],
	"description": "",
	"content": "DynamoDB – Database chính Trong dự án game, chúng ta sẽ dùng DynamoDB để lưu trữ thông tin người chơi, tiến trình chơi và điểm số.\nTạo 3 bảng sau:\nUserProfiles Partition Key (PK): userId UserProgress Partition Key (PK): userId Scores Partition Key (PK): gameArea Sort Key (SK): score Bật DynamoDB Stream\nStream type: NEW IMAGE DevOps cung cấp cho backend Stream ARN để Lambda có thể đọc sự kiện. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.1-workshop-overview/",
	"title": "Tổng quan Workshop",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Workshop Trong workshop này, bạn sẽ học cách triển khai một hệ thống backend cho game bao gồm các thành phần:\nCognito: hệ thống đăng nhập với Username/Password và OAuth (Google). DynamoDB: lưu thông tin người chơi, tiến trình, và điểm số. S3: lưu trữ avatar người chơi, chỉ cho phép upload qua pre-signed URL. Lambda: triển khai các API backend, bao gồm Lambda ZIP thông thường và Lambda Container (OpenCV). API Gateway REST \u0026amp; WebSocket: phục vụ các route REST và realtime leaderboard. CI/CD (CodePipeline + CodeBuild): tự động build container và deploy Lambda. IAM Roles: phân quyền cho Lambda và CodeBuild. CloudWatch: logging, billing alarm, và error alarm cơ bản. Bạn sẽ triển khai từng bước các dịch vụ trên AWS, kiểm tra bằng CLI hoặc console, và cuối cùng thu thập các thông số cần thiết để bàn giao cho FE và BE.\nPhần Lab Cognito – Hệ thống login DynamoDB – Database chính S3 – Lưu avatar người chơi ECR – Container cho Avatar Processing Lambda – API backend API Gateway REST API Gateway WebSocket CI/CD – Backend IAM Roles Logging \u0026amp; Monitoring Yêu cầu Tài khoản AWS có quyền IAM đủ để tạo và cấu hình các dịch vụ trên. Sử dụng khu vực ap-southeast-2 cho workshop. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 2: Tìm hiểu nền tảng AWS Networking thông qua Amazon VPC. Nắm rõ các thành phần trong VPC: Subnets, Route Tables, Internet Gateway, Security Group, NACL. Thực hành workshop thiết kế mạng nội bộ, tạo kết nối internet trong AWS. Làm quen với AWS CLI để thao tác tài nguyên bằng dòng lệnh thay vì giao diện web. Công việc thực hiện trong tuần: Ngày Công việc Bắt đầu Hoàn thành Tài liệu 1 - Tổng quan về Amazon VPC - Xác định dải CIDR phù hợp - Tạo VPC mặc định và truy cập thử nghiệm 16/09/2025 16/09/2025 https://000003.awsstudygroup.com/vi/ 2 - Tạo Public Subnet \u0026amp; Private Subnet - Liên kết Route Table - Gán Internet Gateway cho public subnet 17/09/2025 17/09/2025 https://000004.awsstudygroup.com/vi/ 3 - Thiết lập Security Group cơ bản - Tìm hiểu cơ chế Network ACL - So sánh SG vs NACL ứng dụng thực tế 18/09/2025 18/09/2025 https://000003.awsstudygroup.com/vi/ 4 - Thực hành workshop Networking - Cấu hình NAT Gateway cho private subnet - Thử nghiệm VPC Peering 19/09/2025 19/09/2025 https://000003.awsstudygroup.com/vi/ 5 - Cài đặt AWS CLI - Test CLI commands cơ bản Mini Lab: + Tạo VPC qua CLI + Liệt kê tài nguyên + Xoá VPC bằng CLI 20/09/2025 20/09/2025 https://000011.awsstudygroup.com/vi/ Kết quả đạt được: Hiểu cách hoạt động của VPC và các thành phần mạng trong AWS. Thiết lập được Subnet, Route Table và Internet Gateway một cách thủ công. Nhận biết rõ sự khác biệt giữa Security Group (stateful) và Network ACL (stateless). Hoàn thành lab networking – thao tác cấu hình kết nối nội bộ và internet. Cài đặt AWS CLI thành công và sử dụng để tạo/xoá tài nguyên thay vì thao tác thủ công. Tổng kết: Kết thúc tuần 2, tôi đã:\nTự xây dựng một VPC theo cấu trúc chuẩn gồm public/private subnet. Tạo routing để public subnet ra internet và private subnet đi qua NAT Gateway. Áp dụng security bằng cả Security Group lẫn NACL. Biết chạy lệnh CLI để quản lý tài nguyên nhanh, chính xác hơn so với console. Có nền tảng tốt cho những tuần sau liên quan đến EC2, LoadBalancer và Auto Scaling. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "Serverless Multiplayer Game Backend Một giải pháp AWS có khả năng mở rộng cho game thời gian thực \u0026amp; xử lý AI Avatar\n1. Tóm tắt điều hành Mục tiêu dự án là xây dựng backend serverless cho game multiplayer Unity, hướng đến khả năng mở rộng, độ ổn định cao và tự động hóa triển khai.\nHệ thống được phân chia theo vai trò rõ ràng:\nDevOps – thiết lập hạ tầng AWS \u0026amp; CI/CD Backend (BE) – xử lý API, dữ liệu gameplay và avatar Frontend (Unity) – tương tác Cognito + WebSocket + REST API Các dịch vụ AWS chính được sử dụng:\nAmazon Cognito – đăng nhập \u0026amp; quản lý người dùng AWS Lambda – xử lý logic gameplay API Gateway WebSocket + DynamoDB Streams – leaderboard thời gian thực Lambda Container (OpenCV/MediaPipe) – xử lý avatar bằng AI Kiến trúc này giúp giảm chi phí, tăng tốc phát triển và phù hợp cho triển khai WebGL trên itch.io/CloudFront.\n2. Vấn đề cần giải quyết Vấn đề chính Game multiplayer luôn yêu cầu backend phức tạp gồm xác thực người chơi, đồng bộ dữ liệu, leaderboard tức thời và lưu trữ bền vững.\nNếu triển khai theo mô hình server truyền thống:\nChi phí máy chủ cao dù không có người chơi Cần đội ngũ duy trì vận hành 24/7 Khó scale khi người chơi tăng đột biến Ngoài ra, hệ thống cần xử lý avatar AI (biến đổi khuôn mặt/hình ảnh) – tác vụ nặng, yêu cầu compute linh hoạt.\nGiải pháp đề xuất Xây dựng kiến trúc serverless hoàn toàn trên AWS, gồm:\nCognito quản lý đăng nhập \u0026amp; token identity Lambda xử lý gameplay \u0026amp; nghiệp vụ DynamoDB lưu state người chơi, kết hợp Streams để cập nhật realtime S3 + Lambda Container xử lý avatar bằng OpenCV/MediaPipe Lợi ích \u0026amp; Giá trị đầu tư (ROI) Giá trị Mô tả Chi phí thấp Chỉ trả khi có người dùng tương tác Mở rộng tự động Tăng tải theo số lượng người chơi Dễ triển khai CI/CD push code là cập nhật ngay Phát triển nhanh BE/FE có thể làm song song, không phụ thuộc môi trường 3. Kiến trúc giải pháp Mô hình serverless theo hướng sự kiện (event-driven microservices).\nUnity gọi REST API khi gameplay diễn ra và kết nối WebSocket để nhận leaderboard realtime.\nAvatar được upload qua Presigned URL, xử lý bằng Lambda Container. Các dịch vụ AWS sử dụng Thành phần Dịch vụ Identity Amazon Cognito API Routing API Gateway REST + WebSocket Compute Lambda Zip + Lambda Container Database DynamoDB + Streams Storage S3 Avatar Storage AI Processing ECR Container Image CI/CD CodePipeline + CodeBuild Luồng dữ liệu hoạt động Người dùng đăng nhập → Nhận JWT Token từ Cognito Unity → REST API → Lambda → DynamoDB ghi trạng thái Avatar Upload → Presigned URL → Lưu vào S3 S3 Trigger / BE Trigger → Container Lambda xử lý ảnh Điểm Score thay đổi → DynamoDB Streams → WebSocket broadcast realtime 4. Triển khai kỹ thuật Quy trình triển khai theo giai đoạn Giai đoạn Mục tiêu 1 – Setup hạ tầng Cognito, DynamoDB, S3, API Gateway 2 – Backend Core Lambda API + container xử lý avatar 3 – FE Authentication AuthManager Unity + Signin UI 4 – Kết nối hệ thống API → Lambda → Streams realtime 5 – Gameplay Integration DataManager gọi REST/API WebSocket 6 – E2E Testing Login → Điểm → Leaderboard → Avatar 7 – Deploy WebGL Public WebGL build + domain redirect Yêu cầu kỹ thuật Thành phần Kỹ thuật yêu cầu Frontend Unity C#, AwsConfig, DataManager, WebSocket Client Backend Lambda Python/Node, Docker, Avatar AI DevOps IAM, VPC, API Gateway, CI/CD, CloudWatch 5. Timeline \u0026amp; Milestones Giai đoạn Thời gian Kết quả Phase 1 Day 1–3 Setup Cognito, S3, DynamoDB, API Gateway Phase 2 Day 3–8 Lambda APIs + Avatar AI container Phase 3 Day 8–12 FE tích hợp API + Streams realtime Phase 4 Day 13–15 Test \u0026amp; Deploy WebGL chính thức 6. Ước tính chi phí vận hành Dịch vụ Chi phí dự kiến Lambda Hầu hết trong Free Tier DynamoDB Free Tier 25GB S3 Storage ~0.023 USD/GB CloudWatch Logs ~0.5–1 USD/tháng ECR Storage ~0.10 USD/GB Tổng chi phí phát triển ước tính \u0026lt; 5 USD/tháng\n7. Đánh giá rủi ro Rủi ro Mức ảnh hưởng Xác suất Tích hợp phức tạp Cao Trung bình Độ trễ khi load cao Trung bình Thấp Chi phí phát sinh Thấp Thấp Cách giảm thiểu FE dev bằng mock server khi API chưa sẵn Thay thế leaderboard logic bằng tạm thời nếu BE delay CloudWatch cảnh báo lỗi vượt 10 lần/phút 8. Kết quả kỳ vọng Kỹ thuật đạt được Backend game full serverless Login + dữ liệu người chơi an toàn Leaderboard realtime bằng WebSocket Avatar AI xử lý tự động bằng container Lambda Lợi ích dài hạn Có thể tái sử dụng cho game tiếp theo Không cần quản lý server, tự mở rộng Chi phí thấp, dễ bảo trì "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-dynamodb-s3/5.3.2-s3/",
	"title": "Tạo S3",
	"tags": [],
	"description": "",
	"content": "S3 – Lưu avatar người chơi Tạo bucket S3:\nTên bucket: game-avatars Bật CORS: cho phép PUT, POST, GET từ mọi origin *. Lưu ý: chỉ cho phép upload qua presigned URL do backend tạo.\nLời kết Bạn đã tạo xong 3 bảng DynamoDB và bucket S3. Các thông tin này sẽ được backend sử dụng để lưu trữ dữ liệu người chơi và avatar.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-api-gateway-lambda/5.4.2-websocket-api/",
	"title": "Websocket API",
	"tags": [],
	"description": "",
	"content": "WebSocket API Gateway WebSocket API dùng cho real-time leaderboard.\nCác route:\n$connect → Lambda handler lưu connectionId $disconnect → Lambda handler xóa connectionId broadcast → Lambda handler gửi leaderboard Cấu hình:\nCho phép Lambda đọc connectionId trong DynamoDB. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.2-prerequiste/",
	"title": "Yêu cầu trước",
	"tags": [],
	"description": "",
	"content": "Quyền IAM Thêm chính sách IAM sau vào tài khoản người dùng của bạn để triển khai và quản lý dự án backend game:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;GameProjectPermissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:*\u0026#34;, \u0026#34;apigateway:*\u0026#34;, \u0026#34;cognito-idp:*\u0026#34;, \u0026#34;dynamodb:*\u0026#34;, \u0026#34;s3:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;codebuild:*\u0026#34;, \u0026#34;codepipeline:*\u0026#34;, \u0026#34;logs:*\u0026#34;, \u0026#34;sns:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 3: Hiểu rõ cơ chế hoạt động của Amazon EC2 và các loại instance. Biết cách triển khai, cấu hình và truy cập EC2 trong VPC đã tạo. Tìm hiểu về IAM Role gán cho EC2 để ứng dụng truy cập dịch vụ AWS an toàn. Trải nghiệm môi trường lập trình trực tiếp trên mây thông qua AWS Cloud9. Công việc thực hiện trong tuần: Ngày Nhiệm vụ Bắt đầu Hoàn thành Tài liệu 1 - Tìm hiểu khái niệm EC2 - Phân loại instance theo nhu cầu CPU/RAM - Làm quen với AMI và mục đích sử dụng 23/09/2025 23/09/2025 https://000003.awsstudygroup.com/vi/ 2 - Tạo instance EC2 đầu tiên - Cấu hình Security Group ports (SSH/HTTP) - SSH kết nối vào server 24/09/2025 24/09/2025 https://000003.awsstudygroup.com/vi/ 3 - Tạo IAM Role truy cập S3 - Gán Role cho EC2 thay vì dùng access key - Kiểm tra quyền truy cập S3 trên máy chủ 25/09/2025 25/09/2025 https://000048.awsstudygroup.com/vi/ 4 - Tạo workspace với AWS Cloud9 - Làm quen UI, terminal, editor - Chạy thử code nhỏ (Python/NodeJS) 26/09/2025 26/09/2025 https://000049.awsstudygroup.com/vi/ 5 - Mini Lab: + EC2 + IAM Role truy cập S3 + Deploy web app mẫu trên Cloud9 + Thực hành Stop/Terminate đúng quy trình 27/09/2025 27/09/2025 FCJ Internal Docs, AWS Blogs Kết quả đạt được: Hiểu nguyên lý hoạt động của EC2, AMI và sự khác nhau giữa các loại instance. Tự tay tạo, SSH truy cập và điều khiển EC2 như một máy chủ thật. Cấu hình quyền truy cập S3 bằng IAM Role mà không cần dùng secret keys. Làm quen với Cloud9 – viết code, deploy cơ bản ngay trên nền tảng AWS. Thành thạo thao tác quản lý vòng đời EC2: chạy – dừng – xoá tài nguyên tiết kiệm phí. Tổng kết: Sau tuần 3, tôi đã có thể:\nTriển khai EC2 trong VPC và thiết lập bảo mật thông qua Security Group. Gán IAM Role giúp máy chủ truy cập dịch vụ AWS một cách an toàn. Tự kết nối vào server để cấu hình, chạy ứng dụng và quản lý tài nguyên. Sử dụng Cloud9 như IDE chính cho lập trình backend và deploy thử nghiệm. Nhận thức rõ hơn về chi phí EC2 và cách tối ưu để tránh bị tính phí ngoài ý muốn. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giải thích cách cho dữ liệu trong Aurora PostgreSQL trở nên “hỏi được bằng ngôn ngữ tự nhiên” thông qua Amazon Bedrock Knowledge Bases. Tác giả dùng zero-ETL để tự động sao chép dữ liệu từ Aurora sang Amazon Redshift, sau đó Bedrock Knowledge Bases chuyển câu hỏi tiếng Anh thành SQL, chạy trên Redshift và trả lời lại dưới dạng ngôn ngữ tự nhiên. Bài viết đi qua các bước: tạo schema sample (product, customer, orders), cấu hình zero-ETL, tạo knowledge base và thử hỏi kiểu “Chúng ta có bao nhiêu khách hàng?”.\nBlog 2 - \u0026hellip; Blog này nói về cách dùng Powertools for AWS Lambda (TypeScript) với Parser utility mới để validate payload của các event (SQS, EventBridge, v.v.) một cách chuẩn và dễ bảo trì. Tác giả dùng thư viện Zod để định nghĩa schema (ví dụ orderSchema), sau đó parser sẽ parse + validate event, có thể tự động trích detail/body qua “envelope”, và hỗ trợ safeParse để bạn tự xử lý lỗi, log và đo lường (metrics). Bài cũng minh họa cách mở rộng schema có sẵn, thêm business rule phức tạp bằng .refine().\nBlog 3 - \u0026hellip; BBlog này mô tả một kiến trúc multi-tenant, multi-account cho các use case Generative AI dùng Amazon Bedrock. Tác giả thiết kế một hub account làm cổng vào chung (ALB, Cognito, routing, authz) và nhiều spoke account tách biệt cho từng tenant, kết nối bằng AWS Transit Gateway. Hub nhận request, xác thực, route tới Lambda của tenant, Lambda assume role sang spoke và gọi Bedrock trong VPC riêng, giúp vừa tập trung quản lý (auth, routing) vừa giữ được isolation, quota, chi phí và policy riêng cho từng tenant.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-api-gateway-lambda/5.4.3-lambda/",
	"title": "Lambda",
	"tags": [],
	"description": "",
	"content": "Lambda Functions Chia làm 2 loại:\nLambda thường (ZIP) Dùng cho: score, leaderboard, money, progress, unlock, task. Tạo 1 Lambda function cho mỗi API route. Lambda container Dùng cho avatar AI vì có OpenCV + MediaPipe. Tên đề xuất: AvatarProcessingLambda Cách tạo: Lambda → Create Function → Container Image → chọn image từ ECR. DevOps chỉ tạo function, backend viết code xử lý. Summary Bạn đã tạo xong:\nREST API cho backend WebSocket API cho leaderboard real-time Lambda functions (ZIP + Container) Các thông tin này được gửi cho backend để kết nối và triển khai.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.3-dynamodb-s3/",
	"title": "Tóm tắt về DynamoDB và S3",
	"tags": [],
	"description": "",
	"content": "Database \u0026amp; Storage Summary Trong dự án game, chúng ta sử dụng AWS DynamoDB và AWS S3 để lưu trữ thông tin người chơi và avatar.\nDynamoDB – Main Database DynamoDB được dùng để lưu:\nThông tin hồ sơ người chơi Tiến trình chơi Điểm số theo từng khu vực game Các bảng được tạo UserProfiles\nPartition Key (PK): userId UserProgress\nPartition Key (PK): userId Scores\nPartition Key (PK): gameArea Sort Key (SK): score DynamoDB Streams Bật Stream type: NEW IMAGE DevOps cung cấp Stream ARN cho backend để Lambda có thể xử lý sự kiện. S3 – Store Player Avatars Tạo S3 Bucket Bucket name: game-avatars Bật CORS: Cho phép PUT, POST, GET Origin: * Lưu ý Chỉ cho phép upload thông qua presigned URL do backend sinh ra. Tổng kết Bạn đã thiết lập:\n3 bảng DynamoDB 1 S3 bucket để lưu avatar người chơi Những tài nguyên này sẽ được backend sử dụng để lưu trữ dữ liệu người chơi một cách an toàn và hiệu quả.\nNội dung Tạo DynamoDB Tạo S3 Bucket "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 4: Làm quen với dịch vụ lưu trữ tệp Amazon S3 và cách triển khai web tĩnh. Khám phá Amazon Lightsail như một mô hình đám mây đơn giản hơn EC2. Triển khai ứng dụng dạng container thông qua Lightsail Containers. Áp dụng thực hành triển khai ứng dụng thực tế trên môi trường cloud. Công việc thực hiện trong tuần: Ngày Nhiệm vụ Bắt đầu Hoàn thành Tài liệu 1 - Tìm hiểu kiến trúc Amazon S3 - Nắm bucket, object, storage class - Cấu hình S3 website hosting 30/09/2025 30/09/2025 https://000057.awsstudygroup.com/vi/ 2 - Thực hành hosting web tĩnh: + Upload file HTML/CSS/JS + Public access bucket + Chạy thử qua link S3 01/10/2025 01/10/2025 https://000057.awsstudygroup.com/vi/ 3 - Giới thiệu Amazon Lightsail - So sánh tính năng với EC2 - Tạo instance thử nghiệm 02/10/2025 02/10/2025 https://000045.awsstudygroup.com/vi/ 4 - Tìm hiểu Lightsail Containers - Cơ bản về container image và deployment - Triển khai app container đầu tiên 03/10/2025 03/10/2025 https://000046.awsstudygroup.com/vi/ 5 - Mini Lab tổng hợp: + Deploy website hoàn chỉnh bằng S3 + Deploy app container trên Lightsail + So sánh chi phí S3 / Lightsail / EC2 + Dọn dẹp resource tránh phát sinh phí 04/10/2025 04/10/2025 https://000057.awsstudygroup.com/vi/ Kết quả đạt được: Tự triển khai một web tĩnh trên S3, truy cập public thành công. Biết cách cấu hình bucket policy, cấp quyền và tối ưu public access. Hiểu cơ chế hoạt động của Lightsail và khi nào nên dùng thay EC2. Tự triển khai ứng dụng container trên Lightsail Containers. Đánh giá được sự khác biệt chi phí giữa S3, Lightsail và EC2 tuỳ nhu cầu dự án. Tổng kết: Kết thúc tuần 4, tôi có thể:\nHost website trên S3 và tự cấu hình permission, bucket policy. Triển khai ứng dụng nhanh bằng Lightsail thay vì cấu hình EC2 thủ công. Build \u0026amp; deploy ứng dụng container lên Lightsail Containers. Lựa chọn dịch vụ phù hợp giữa S3 – Lightsail – EC2 dựa theo độ phức tạp và chi phí. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTrong phần này, các bạn cần liệt kê và mô tả chi tiết các sự kiện (event) mà mình đã tham gia trong suốt quá trình thực tập hoặc làm việc.\nMỗi sự kiện nên được trình bày theo định dạng Event 1, Event 2, Event 3…, kèm theo các thông tin:\nTên sự kiện Thời gian tổ chức Địa điểm (nếu có) Vai trò của bạn trong sự kiện (người tham dự, hỗ trợ tổ chức, diễn giả, v.v.) Mô tả ngắn gọn nội dung và hoạt động chính trong sự kiện Kết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án) Việc liệt kê này giúp thể hiện rõ sự tham gia thực tế của bạn, cũng như các kỹ năng mềm và kinh nghiệm bạn đã tích lũy qua từng sự kiện. Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian: 09:00 ngày 13/08/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.4-api-gateway-lambda/",
	"title": "Tổng Quan API &amp; Lambda",
	"tags": [],
	"description": "",
	"content": "Tổng Quan API \u0026amp; Lambda Mục này tóm tắt toàn bộ hệ thống API và dịch vụ xử lý backend cho dự án game.\nHệ thống bao gồm:\nREST API Gateway – API chính để game giao tiếp với backend WebSocket API Gateway – Cập nhật bảng xếp hạng theo thời gian thực AWS Lambda Functions – Xử lý logic game và AI Avatar Dưới đây là phần mô tả tổng hợp của ba thành phần này.\nREST API Gateway – Lớp API chính của backend REST API kết nối frontend (Unity/Web) với các Lambda function phía backend.\nCác endpoint chính POST /score GET /leaderboard GET /leaderboard/global POST /progress POST /unlock POST /task/complete POST /money/add POST /shop/buy POST /avatar/presign POST /avatar/update POST /avatar/process (gọi Lambda dạng container để xử lý avatar) Cấu hình Bật CORS cho tất cả route Tạo JWT Authorizer kết nối với Amazon Cognito Gán từng route với đúng Lambda function REST API đảm bảo giao tiếp bảo mật và rõ ràng giữa game và backend.\nWebSocket API – Bảng xếp hạng thời gian thực WebSocket API dùng để cập nhật leaderboard theo thời gian thực mà không cần polling.\nCác route $connect → lưu connectionId $disconnect → xóa connectionId broadcast → gửi dữ liệu bảng xếp hạng cho tất cả client Cấu hình Lambda đọc danh sách connectionId từ DynamoDB Phù hợp cho game cần cập nhật điểm liên tục Dịch vụ này giúp game hiển thị bảng xếp hạng realtime.\nLambda Functions – Xử lý logic game Hệ thống sử dụng hai loại Lambda:\n1. Lambda dạng ZIP Dùng cho các chức năng logic game tiêu chuẩn:\nđiểm số leaderboard tiền tệ người chơi lưu tiến trình mở khóa nội dung nhiệm vụ Mỗi API route có một Lambda riêng để tách biệt logic rõ ràng.\n2. Lambda dạng Container Dùng cho xử lý nặng, đặc biệt AI Avatar:\nOpenCV + MediaPipe Tên gợi ý: AvatarProcessingLambda Được deploy từ image trên ECR.\nDevOps tạo function, backend triển khai code xử lý.\nTổng kết Bạn đã thiết lập:\nREST API phục vụ các tác vụ backend WebSocket API cho realtime leaderboard Hệ thống Lambda (ZIP + Container) xử lý logic game và avatar AI Ba thành phần này tạo nên hạ tầng backend cốt lõi cho dự án game, giúp xử lý dữ liệu, giao tiếp real-time và tạo avatar thông minh.\n"
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 5: Hiểu cơ chế hoạt động của Amazon RDS và khi nào nên dùng CSDL quan hệ. Triển khai, cấu hình và kết nối thử nghiệm RDS instance trong môi trường VPC. Làm quen với Amazon DynamoDB – NoSQL với hiệu năng cao \u0026amp; tối ưu scale. So sánh ưu nhược điểm RDS vs DynamoDB để lựa chọn đúng ngữ cảnh hệ thống. Công việc thực hiện trong tuần: Ngày Nhiệm vụ Bắt đầu Hoàn thành Tài liệu 1 - Giới thiệu tổng quan Amazon RDS - Tìm hiểu MySQL/PostgreSQL engines - Multi-AZ, Read Replica hoạt động thế nào? 07/10/2025 07/10/2025 https://000005.awsstudygroup.com/vi/ 2 - Khởi tạo RDS instance đầu tiên - Thiết lập Security Group truy cập hợp lệ - Kết nối RDS từ EC2 qua MySQL Workbench/CLI 08/10/2025 08/10/2025 https://000005.awsstudygroup.com/vi/4-create-rds/ 3 - Tìm hiểu snapshot và cơ chế backup tự động - Restore DB thử nghiệm từ snapshot - Test khả năng phục hồi dữ liệu 09/10/2025 09/10/2025 https://000005.awsstudygroup.com/vi/6-backup/ 4 - Làm quen DynamoDB - Kiến trúc NoSQL, Partition Key/Sort Key - Tạo bảng và chạy thử truy vấn 10/10/2025 10/10/2025 https://000060.awsstudygroup.com/vi/ 5 - Mini lab: + Tạo RDS MySQL và thao tác CRUD + Tạo DynamoDB table, đọc/ghi dữ liệu + So sánh tốc độ đọc ghi RDS vs DynamoDB + Cleanup resource tránh phát sinh phí 11/10/2025 11/10/2025 https://000005.awsstudygroup.com/vi/5-deploy-app/ Kết quả đạt được: Hiểu được cơ chế RDS vận hành, replicate và backup dữ liệu. Tạo RDS instance, mở kết nối và chạy truy vấn thử thành công. Biết cách khôi phục dữ liệu DB từ snapshot và tự động backup. Tạo bảng DynamoDB và thực hiện CRUD bằng console \u0026amp; SDK. Có cái nhìn thực tế hơn về hiệu năng giữa CSDL quan hệ và NoSQL. Tổng kết: Sau tuần 5, tôi đã:\nVận hành được RDS MySQL từ khâu tạo – kết nối – vận hành – backup. Biết sử dụng Security Group để giới hạn truy cập DB an toàn. Hiểu snapshot/restore dùng trong kịch bản sự cố hoặc rollback. Thiết kế bảng DynamoDB phù hợp với khối lượng truy vấn lớn. Đánh giá được khi nào nên chọn RDS (transaction mạnh) hay DynamoDB (scale lớn, latency thấp). "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.5-ci-cd/",
	"title": "CI/CD Deployment cho Backend",
	"tags": [],
	"description": "",
	"content": "Mục tiêu Trong phần này, bạn sẽ cấu hình pipeline tự động để deploy backend, bao gồm cả Lambda thường và Lambda container (AvatarProcessingLambda). CI/CD giúp đảm bảo code luôn được triển khai với quyền IAM chính xác và dịch vụ luôn sẵn sàng.\n1. Chuẩn bị GitHub Repo của backend ECR Repository cho Lambda container (AvatarProcessingLambda) IAM Role cho CodeBuild với quyền: ECR push/pull, Lambda update 2. Tạo CodePipeline Vào AWS CodePipeline → Create Pipeline Đặt tên Pipeline (ví dụ: GameBackendPipeline) Chọn Source: GitHub repo backend Chọn Build: CodeBuild 3. Cấu hình CodeBuild Environment: Managed image + Docker Buildspec.yml ví dụ: version: 0.2 phases: pre_build: commands: - echo Logging in to Amazon ECR... - aws ecr get-login-password --region ap-southeast-2 | docker login --username AWS --password-stdin 254670366571.dkr.ecr.ap-southeast-2.amazonaws.com build: commands: - echo Build Docker image... - docker build -t avatar-processing . - docker tag avatar-processing:latest 254670366571.dkr.ecr.ap-southeast-2.amazonaws.com/avatar-processing:latest post_build: commands: - echo Push Docker image to ECR... - docker push 254670366571.dkr.ecr.ap-southeast-2.amazonaws.com/avatar-processing:latest - echo Deploy to Lambda... - aws lambda update-function-code --function-name AvatarProcessingLambda --image-uri 254670366571.dkr.ecr.ap-southeast-2.amazonaws.com/avatar-processing:latest "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Tổng quan Workshop: Triển khai Backend cho Game Mục tiêu chung Workshop này hướng dẫn từng bước cách triển khai backend cho một dự án game (Unity/Web) trên AWS. Sau khi hoàn thành bạn sẽ có:\nHệ thống đăng nhập (Cognito) với username/password và OAuth (Google). Cơ sở dữ liệu NoSQL dùng DynamoDB cho profile, tiến trình và điểm số. Lưu trữ avatar người chơi trên S3, upload thông qua presigned URL. Các hàm xử lý (Lambda) dạng ZIP cho logic nhẹ và Container Lambda (OpenCV/MediaPipe) cho xử lý ảnh/AI. API Gateway (REST) cho các route gameplay; API Gateway (WebSocket) cho realtime leaderboard. CI/CD (CodePipeline + CodeBuild) để build container, đẩy lên ECR và cập nhật Lambda. Cấu hình IAM, CloudWatch (log, báo lỗi, alarm) và tuỳ chọn WAF. Phần Lab (structure) Cognito — xây hệ thống đăng nhập và authorizer JWT. DynamoDB — tạo các bảng: UserProfiles, UserProgress, Scores (PK/SK tương ứng). S3 — tạo bucket game-avatars, bật CORS, chỉ cho upload qua presigned URL. ECR — repo để chứa image phục vụ Container Lambda (AvatarProcessing). Lambda — tạo các function ZIP cho API và Container Lambda cho xử lý nặng. API Gateway (REST) — khai báo route, map mỗi route tới Lambda, bật CORS. API Gateway (WebSocket) — quản lý kết nối realtime cho leaderboard. CI/CD — thiết lập CodePipeline + CodeBuild để tự động build \u0026amp; deploy. IAM Roles — tạo role phù hợp cho các service (Lambda, CodeBuild, CodePipeline). Logging \u0026amp; Monitoring — CloudWatch log group, alarm billing \u0026amp; error. WAF — (tùy chọn) bảo vệ API. Chi tiết kỹ thuật quan trọng DynamoDB Bảng chính: UserProfiles (PK: userId) UserProgress (PK: userId) Scores (PK: gameArea, SK: score) Streams: NEW_IMAGE để Lambda/consumer xử lý event realtime. S3 Bucket: game-avatars CORS: cho phép PUT, POST, GET và origin * (cấu hình production cần thu hẹp). Uploads thực hiện bằng presigned URL do backend cấp. API \u0026amp; Lambda REST endpoints tiêu biểu: POST /score, GET /leaderboard, GET /leaderboard/global POST /progress, POST /unlock, POST /task/complete POST /money/add, POST /shop/buy POST /avatar/presign, POST /avatar/update, POST /avatar/process WebSocket routes: $connect, $disconnect, broadcast — lưu/xóa connectionId trong DynamoDB. Lambda types: ZIP Lambdas: scoring, progress, shop, leaderboard. Container Lambda: AvatarProcessingLambda (OpenCV + MediaPipe) — deployed từ ECR image. CI/CD (CodePipeline + CodeBuild) Source: GitHub repo Build: CodeBuild (Docker enabled) → build image → tag → push ECR → update Lambda image. Ví dụ buildspec.yml đã được cung cấp để đăng nhập ECR, build \u0026amp; push image, gọi aws lambda update-function-code. Nội dung Tổng quan về workshop Chuẩn bị Tạo DynamoDB và S3 Bucket Tạo API Gateway và Lambda 1 chút về CI/CD Dọn dẹp tài nguyên "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 6: Làm quen với Amazon ElastiCache và vai trò của cache trong hệ thống phân tán. Hiểu cách ứng dụng Redis/Memcached để tăng tốc độ truy vấn dữ liệu. Tích hợp thử nghiệm ElastiCache với các dịch vụ đã học tuần trước. Ôn tập lại kiến thức Database (RDS + DynamoDB) để kết hợp với Cache phục vụ bài toán hiệu năng. Nhiệm vụ thực hiện trong tuần: Ngày Công việc Bắt đầu Hoàn thành Tài liệu tham khảo 1 - Tổng quan ElastiCache - Sự khác nhau giữa Redis \u0026amp; Memcached - Tư duy cache-first và cache-aside pattern 14/10/2025 14/10/2025 https://000061.awsstudygroup.com/vi/1-introduce/ 2 - Khởi tạo Redis Cluster trên ElastiCache - Cấu hình Security Group kết nối VPC - Kết nối thử từ EC2 15/10/2025 15/10/2025 https://000061.awsstudygroup.com/vi/3-amazonelasticacheforredis/3.4-grantaccesstocluster/ 3 - Thêm lớp Cache vào ứng dụng - Cache Invalidation (TTL, manual invalidation) - Theo dõi chỉ số hit/miss 16/10/2025 16/10/2025 AWS Caching Guidelines, FCJ Notes 4 - Bài lab tích hợp thực tế: + Kết nối RDS + Redis + Lưu session \u0026amp; cache query + Test tốc độ phản hồi 17/10/2025 17/10/2025 AWS Architecture Labs 5 - Mini practice: + Deploy hệ thống 3-tier (EC2 → Redis → RDS) + Benchmark tốc độ có/không dùng cache + Review lại kiến trúc DB \u0026amp; tối ưu chi phí + Thu dọn tài nguyên tránh phát sinh phí 18/10/2025 18/10/2025 Well-Architected Framework, FCJ Session Kết quả đạt được: Nắm được cách hoạt động của In-memory Cache và lý do hệ thống lớn luôn cần Redis. Phân biệt rõ ràng giữa Redis (session/state cache) và Memcached (memory-key store đơn giản). Tự xây dựng Caching Layer để giảm số lượng truy vấn DB. Kết hợp ElastiCache + RDS → tốc độ truy vấn cải thiện đáng kể. Hoàn thiện demo hệ thống web có khả năng scale và tối ưu tải. Tổng kết: Kết thúc tuần 6, tôi đã có thể:\nTự tạo và kết nối ElastiCache Cluster trong VPC riêng. Thiết kế cơ chế cache hợp lý cho API và database truy vấn thường xuyên. Tích hợp Redis vào ứng dụng để lưu session/login state, query caching. Đo đạc hiệu năng và đánh giá mức giảm tải khi sử dụng cache. Có cái nhìn rõ ràng hơn về việc kết hợp RDS + DynamoDB + Redis trong kiến trúc thực tế. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/5-workshop/5.6-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "5.6 Dọn dẹp môi trường Workshop Sau khi hoàn thành workshop, hãy dọn dẹp môi trường để tránh phát sinh chi phí không cần thiết trên AWS.\nXóa các Lambda Functions Vào AWS Lambda Console. Chọn tất cả các Lambda Functions bạn đã tạo: AvatarProcessingLambda BroadcastHandler ConnectHandler DisconnectHandler LeaderboardFunction MoneyFunction ProgressFunction ScoreFunction TaskFunction UnlockFunction Chọn Actions → Delete và xác nhận. Xóa API Gateway Vào API Gateway Console. Chọn REST API và WebSocket API của workshop. Chọn Actions → Delete API và xác nhận. Xóa S3 Buckets Vào S3 Console. Xóa tất cả các bucket đã tạo: game-avatars Các bucket phục vụ workshop (bucket-1, bucket-2,…) Lưu ý xóa toàn bộ nội dung bên trong trước khi xóa bucket. Xóa DynamoDB Tables Vào DynamoDB Console. Xóa các bảng: UserProfiles UserProgress Scores Xác nhận xóa từng bảng. Xóa IAM Roles Vào IAM Console → Roles. Xóa các Role đã tạo cho workshop: Lambda Execution Role CodeBuild Role Đảm bảo không còn Policy nào gắn với Role trước khi xóa. Xóa ECR Repositories Vào ECR Console. Xóa repository avatar-processing. Xác nhận xóa toàn bộ images trong repository. Xóa CodePipeline / CodeBuild Vào CodePipeline Console. Xóa pipeline workshop. Xóa project CodeBuild tương ứng. Kiểm tra chi phí Truy cập AWS Billing Console → Cost Explorer. Đảm bảo không còn dịch vụ nào phát sinh chi phí từ workshop. Nếu còn dịch vụ nào tồn tại, xóa theo hướng dẫn tương ứng. Tóm tắt Môi trường workshop đã được dọn dẹp hoàn toàn. Không còn Lambda, API, S3, DynamoDB, IAM Role, ECR, hay pipeline nào tồn tại. Chi phí phát sinh từ workshop đã được giảm về 0. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": " ⚠️ Lưu ý: Nội dung dưới đây chỉ mang tính tham khảo, vui lòng không sao chép nguyên văn cho báo cáo chính thức, bao gồm cả cảnh báo này.\nTrong thời gian thực tập tại FCJ AWS kéo dài từ 8/9/2025 đến 9/12/2025, tôi được trực tiếp tham gia môi trường làm việc thực tế, vận dụng những kiến thức đã học và tiếp thu thêm nhiều quy trình mới trong doanh nghiệp.\nTôi đảm nhận công việc làm game 2D endless runner với tích hợp các dịch vụ AWS, từ đó tôi cải thiện rõ rệt về kỹ năng lập trình, thao tác công cụ, kỹ năng teamwork, giao tiếp báo cáo tiến độ.\nNgoài chuyên môn, tôi học được cách quản lý công việc, phân chia thời gian, trao đổi với mentor và phối hợp với các thành viên trong nhóm để hoàn thành mục tiêu sprint. Tôi luôn cố gắng chủ động trong công việc, tìm hiểu trước tài liệu, đặt câu hỏi khi cần và tuân thủ các quy định nội bộ.\nDưới đây là phần tự đánh giá mức độ phát triển bản thân trong suốt kỳ thực tập:\nSTT Tiêu chí đánh giá Mô tả Tốt Khá TB 1 Kiến thức chuyên môn Hiểu được quy trình, công cụ dự án, ứng dụng vào thực tế ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu công nghệ mới, tự nghiên cứu tương đối tốt ☐ ✅ ☐ 3 Chủ động trong công việc Tự đề xuất nhiệm vụ, không phụ thuộc hoàn toàn vào hướng dẫn ✅ ☐ ☐ 4 Trách nhiệm Hoàn thành task theo deadline, hạn chế lỗi phát sinh ✅ ☐ ☐ 5 Tính kỷ luật Đôi lúc còn trễ deadline nhỏ cần cải thiện thêm ☐ ☐ ✅ 6 Tinh thần cầu tiến Luôn hỏi thêm mentor để hoàn thiện kỹ năng ☐ ✅ ☐ 7 Giao tiếp – báo cáo Có thể trao đổi rõ ý, nhưng cần tự tin hơn khi trình bày ☐ ✅ ☐ 8 Làm việc nhóm Hỗ trợ đồng đội, review code và chia sẻ kiến thức ✅ ☐ ☐ 9 Tác phong – thái độ Tôn trọng quy tắc công ty, hợp tác dễ dàng ✅ ☐ ☐ 10 Giải quyết vấn đề Đã biết phân tích lỗi, nhưng khả năng đề xuất giải pháp còn hạn chế ☐ ✅ ☐ 11 Đóng góp cho dự án Tham gia triển khai tính năng và ghi nhận kết quả tích cực ✅ ☐ ☐ 12 Tổng quan Tự đánh giá quá trình thực tập khá hiệu quả và tiến bộ ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỷ luật để bám sát deadline hơn Tập trung tư duy phân tích lỗi \u0026amp; tối ưu giải pháp Rèn luyện giao tiếp khi trình bày báo cáo hoặc đề xuất ý tưởng "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Tìm hiểu cơ chế EC2 Auto Scaling nhằm duy trì hiệu năng ứng dụng khi tải tăng hoặc giảm. Khởi tạo và cấu hình Auto Scaling Group kết hợp Launch Template. Làm quen Amazon CloudWatch để theo dõi tài nguyên theo thời gian thực. Thiết lập scaling policies tự động dựa trên chỉ số giám sát. Công việc thực hiện trong tuần: Ngày Nhiệm vụ Bắt đầu Hoàn thành Tài liệu tham khảo 1 - Nắm khái niệm Auto Scaling - Phân loại chính sách scaling: Target tracking / Step / Scheduled - Tìm hiểu Launch Template 21/10/2025 21/10/2025 https://000006.awsstudygroup.com/vi/ 2 - Tạo Launch Template tùy chỉnh - Khởi tạo Auto Scaling Group trong VPC - Cấu hình Min–Desired–Max Capacity 22/10/2025 22/10/2025 https://000006.awsstudygroup.com/vi/6-create-auto-scaling-group/ 3 - Nghiên cứu CloudWatch Metrics \u0026amp; Namespaces - Tạo Dashboard theo dõi hoạt động EC2 23/10/2025 23/10/2025 https://000008.awsstudygroup.com/vi/ 4 - Tạo CloudWatch Alarm theo CPU Utilization - Kết nối cảnh báo qua SNS email - Gán alarm cho scaling policy 24/10/2025 24/10/2025 https://000008.awsstudygroup.com/vi/5-cloud-watch-alarm/ 5 - Bài thực hành tổng hợp: + Tạo Auto Scaling Group + Policy tự động + Tải test để kích hoạt scaling + Theo dõi sự thay đổi instance trên CloudWatch Activity Log + Thu hồi tài nguyên sau khi kiểm thử 25/10/2025 25/10/2025 FCJ Training Notes, Monitoring Best Practices Kết quả đạt được: Hiểu sâu hơn về cách hoạt động của EC2 Auto Scaling và các loại policy khác nhau. Tự tạo và cấu hình Launch Template + Auto Scaling Group phục vụ load thực tế. Xây dựng Dashboard quan sát CPU, Network, Status Checks trên CloudWatch. Thiết lập cảnh báo tự động thông qua CloudWatch Alarm + SNS Notification. Mô phỏng tải và quan sát hệ thống tự scale-out/scale-in hiệu quả. Tổng kết: Sau tuần 7, tôi đã có thể:\nTự triển khai hệ thống Auto Scaling để duy trì hiệu năng dịch vụ. Xác định và chọn scaling policy phù hợp theo nhu cầu tải ứng dụng. Theo dõi tài nguyên bằng Dashboard và sử dụng cảnh báo để phản hồi kịp thời. Thử nghiệm tình huống tăng tải và quan sát cơ chế scale tự động. Tối ưu hướng vận hành EC2 theo tiêu chí tiết kiệm chi phí và đảm bảo uptime. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc Môi trường tại FCJ rất thoải mái và dễ hòa nhập. Mọi người trong cộng đồng FCJ thân thiện, sẵn sàng hỗ trợ khi tôi gặp khó khăn, kể cả ngoài giờ làm. Không gian làm việc sạch sẽ, bố trí hợp lý giúp tôi tập trung tốt hơn.\n2. Sự hỗ trợ của mentor / team admin Mentor hướng dẫn rõ ràng, giải thích chi tiết mỗi khi tôi chưa nắm được vấn đề, đồng thời tạo điều kiện để tôi tự tìm hiểu và xử lý trước khi đưa ra hướng đi. Team mentor hỗ trợ thủ tục nhanh gọn, cung cấp tài liệu và công cụ làm việc đầy đủ. Tôi đánh giá cao sự kiên nhẫn và cách mentor giúp tôi tự phát triển thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCác nhiệm vụ tôi được giao có sự liên kết với kiến thức học ở trường, đặc biệt là về quy trình phát triển phần mềm và xử lý dữ liệu. Bên cạnh đó, tôi còn được làm quen với những công nghệ mới — giúp bổ sung khoảng trống giữa lý thuyết và thực tiễn.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng Thực tập tại FCJ giúp tôi cải thiện khả năng quản lý task, sử dụng công cụ hỗ trợ phát triển dự án, và rèn luyện cách phối hợp trong nhóm. Mentor chia sẻ nhiều tình huống thực tế trong công việc, qua đó tôi định hình rõ hơn hướng đi nghề nghiệp trong tương lai.\n5. Văn hóa \u0026amp; tinh thần đồng đội Tập thể làm việc nghiêm túc nhưng không căng thẳng, mọi người tôn trọng ý kiến nhau và sẵn sàng hỗ trợ khi cần. Khi workload tăng, cả team cùng cố gắng thay vì chia tách trách nhiệm. Điều này giúp tôi cảm thấy mình là một phần của tập thể dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nChương trình thực tập mang đến môi trường học tập thuận lợi với cơ sở vật chất đầy đủ, tài liệu hỗ trợ, và sự hướng dẫn tận tâm từ mentor, giúp tôi phát triển tốt trong suốt quá trình thực tập. Một số câu hỏi khác Điều tôi hài lòng nhất trong kỳ thực tập là được tiếp cận quy trình thực tế và được mentor hướng dẫn tận tâm. Công ty có thể mở rộng thêm hoạt động chia sẻ kiến thức giữa các nhóm để tăng cơ hội trao đổi học hỏi. Nếu có bạn bè có nhu cầu thực tập, tôi sẵn sàng giới thiệu vì môi trường thân thiện và hỗ trợ phát triển kỹ năng tốt. Đề xuất \u0026amp; mong muốn Mong muốn có thêm workshop nội bộ về công nghệ mới để mở rộng kiến thức. Tôi sẵn sàng tiếp tục tham gia chương trình trong tương lai nếu có cơ hội. Trải nghiệm thực tập giúp tôi trưởng thành hơn trong tư duy và kỹ năng — xin cảm ơn công ty vì sự đồng hành trong suốt thời gian qua. chuyển sang tiếng anh "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Tìm hiểu hệ thống Amazon Route 53 và cách quản lý DNS trong môi trường cloud. Làm quen với Amazon CloudFront – dịch vụ CDN giúp phân phối nội dung nhanh hơn. Nắm được cơ chế hoạt động của Lambda@Edge để xử lý logic ngay tại Edge Location. Xây dựng mô hình phân phối nội dung toàn cầu với độ trễ thấp và độ tin cậy cao. Công việc thực hiện trong tuần: Ngày Nhiệm vụ Bắt đầu Hoàn thành Tài liệu tham khảo 1 - Tổng quan Route 53 - Ôn lại khái niệm DNS, bản ghi A, CNAME, alias - Tạo hosted zone và record đơn giản 28/10/2025 28/10/2025 https://000010.awsstudygroup.com/vi/ 2 - Áp dụng các routing policy: Simple, Weighted, Failover - Cài đặt Health Check để thực hiện dự phòng DNS 29/10/2025 29/10/2025 https://000010.awsstudygroup.com/vi/2-prerequiste/ 3 - Làm quen CloudFront CDN - Tìm hiểu Edge Location \u0026amp; Cache TTL - Tạo CloudFront Distribution đầu tiên 30/10/2025 30/10/2025 https://000094.awsstudygroup.com/vi/ 4 - Kết nối CloudFront với S3 origin - Gán tên miền riêng thông qua Route 53 - Cấp chứng chỉ SSL bằng ACM 31/10/2025 31/10/2025 https://000094.awsstudygroup.com/vi/1.-cloud-front-với-s3/ 5 - Tìm hiểu Lambda@Edge - Thực hành: Tạo CloudFront + domain riêng + SSL - Triển khai Lambda@Edge xử lý request/response - Đánh giá tốc độ và khả năng phân phối của CDN 01/11/2025 01/11/2025 https://000130.awsstudygroup.com/vi/ Kết quả đạt được: Hiểu cách quản lý DNS, bản ghi, Hosted Zone bằng Route 53. Thiết lập Routing Policies phục vụ high-availability và failover. Triển khai CloudFront thành công để phân phối nội dung toàn cầu. Ứng dụng Lambda@Edge để xử lý logic ngay tại biên mạng. Kết hợp Route 53 + CloudFront + SSL + Edge Computing thành một CDN hoàn chỉnh. Tổng kết: Kết thúc tuần 8, tôi đã có thể:\nTối ưu phân phối nội dung với Route 53 và CloudFront. Tạo chứng chỉ SSL/TLS bằng ACM và cấu hình cho domain tùy chỉnh. Sử dụng Lambda@Edge để tùy biến phản hồi người dùng theo request headers/path. Xây dựng mô hình CDN giảm độ trễ truy cập cho người dùng ở nhiều khu vực khác nhau. Có cái nhìn tổng quan về kiến trúc global scale phục vụ web/app real-time. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Tiếp cận mô hình vận hành Windows Workloads trên AWS. Khởi tạo và quản trị Windows Server chạy trên EC2. Làm quen với AWS Managed Microsoft AD để quản lý danh tính tập trung. Thử nghiệm tích hợp Windows với các dịch vụ AWS phục vụ doanh nghiệp. Công việc thực hiện trong tuần: Ngày Nhiệm vụ Bắt đầu Hoàn thành Tài liệu tham khảo 1 - Ôn tập kiến thức Windows on AWS - Hiểu cơ chế license Windows khi chạy EC2 - Tạo EC2 Windows Server đầu tiên 04/11/2025 04/11/2025 https://000093.awsstudygroup.com/vi/ 2 - Kết nối Windows EC2 bằng Remote Desktop (RDP) - Cài đặt roles/features cần thiết - Triển khai IIS Web Server trên Windows 05/11/2025 05/11/2025 FCJ Notes, AWS Windows Hands-on 3 - Nghiên cứu AWS Managed Microsoft AD - Nắm cấu trúc AD, Domain, OU, Group - Tạo directory service trên AWS 06/11/2025 06/11/2025 AWS Directory Service Docs 4 - Join Windows EC2 vào Domain - Tạo user, group \u0026amp; phân quyền - Cấu hình Group Policy để quản lý tập trung 07/11/2025 07/11/2025 AWS Managed AD Whitepaper 5 - Bài thực hành tổng hợp: + Deploy ứng dụng Windows lên EC2 + Tích hợp Managed AD cho xác thực tập trung + Test đăng nhập domain + SSO + Xây dựng quy trình quản trị user 08/11/2025 08/11/2025 AWS Enterprise Patterns, FCJ Workshop Kết quả đạt được: Khởi tạo và quản lý thành công Windows Server trên EC2. Kết nối bằng RDP, cài đặt IIS và triển khai ứng dụng mẫu trên Windows. Tạo và vận hành AWS Managed Microsoft AD phục vụ quản lý danh tính. Gắn Windows EC2 vào domain, quản lý User/Group tập trung. Thực hành quản trị cơ bản qua Group Policy và SSO. Tổng kết: Kết thúc tuần 9, tôi đã có thể:\nTự triển khai workload Windows Server trên AWS. Cài đặt IIS và host ứng dụng trực tiếp trên Windows EC2. Xây dựng Directory Service bằng Managed AD và áp dụng vào thực tế. Join máy chủ vào domain để quản lý user và authentication. Vận hành môi trường Windows trong AWS với hướng tiếp cận chuẩn doanh nghiệp. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Nắm vững mô hình kết nối Active Directory trong môi trường Hybrid. Triển khai liên thông giữa AWS Managed Microsoft AD và hệ thống AD nội bộ. Tìm hiểu và sử dụng AD Connector \u0026amp; Simple AD trong các tình huống thực tế. Thực hành xử lý lỗi, giám sát và tối ưu hệ thống directory. Workload trong tuần: Day Task Start Done Reference 1 - Ôn tập kiến trúc Hybrid Active Directory - Hiểu cơ chế Trust giữa Domain - Thiết lập mô hình Trust cơ bản 11/11/2025 11/11/2025 AWS Hybrid AD Docs 2 - Nghiên cứu AD Connector - So sánh Managed AD – AD Connector – Simple AD - Kết nối thử với AD nội bộ 12/11/2025 12/11/2025 AWS Directory Service Overview 3 - Cấu hình Cross-domain Auth - Tích hợp đăng nhập tập trung (SSO) - Liên kết với AWS WorkSpaces 13/11/2025 13/11/2025 AWS SSO Docs 4 - Thực hành xử lý lỗi directory - Theo dõi trạng thái domain, replication - Thiết lập cơ chế backup \u0026amp; rollback 14/11/2025 14/11/2025 AWS Managed AD Best Practices 5 - Mini lab tổng kết: + Triển khai Hybrid AD hoàn chỉnh + Thiết lập trust hai chiều + Test auth \u0026amp; SSO + Tổng hợp use case thực tế 15/11/2025 15/11/2025 AWS Enterprise Architecture Notes Week 10 Outcomes: Nắm chắc nguyên tắc vận hành Hybrid Directory Infrastructure. Tự cấu hình Domain Trust giữa AWS và môi trường on-premises. Hiểu rõ khi nào dùng Managed AD, AD Connector hoặc Simple AD. Tích hợp xác thực tập trung (SSO) cho ứng dụng trong AWS. Có khả năng giám sát, debug và khôi phục directory khi phát sinh lỗi. Summary: Đến cuối tuần 10, tôi đã có thể:\nThiết kế mô hình Hybrid AD phục vụ bài toán doanh nghiệp. Kết nối Active Directory on-premises với AWS Directory Service. Triển khai SSO và xác thực liên domain cho ứng dụng. Lựa chọn dịch vụ Directory phù hợp với từng yêu cầu thực tế. Theo dõi, bảo trì và xử lý tình huống sự cố trong môi trường sản xuất. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Hiểu sâu hơn về mô hình High Availability (HA) trong hệ thống cloud. Thiết kế và vận hành kiến trúc web nhiều tầng (multi-tier). Làm quen và so sánh các loại Elastic Load Balancer (ALB, NLB, CLB). Triển khai cơ chế backup, replication \u0026amp; disaster recovery cho ứng dụng. Weekly Task Breakdown: Day Task Start Done References 1 - Tổng quan HA trong cloud - Khái niệm fault tolerance, resilience - Nghiên cứu Reliability Pillar trong Well-Architected 18/11/2025 18/11/2025 AWS Well-Architected Docs 2 - Học ELB chi tiết - Phân biệt ALB, NLB, CLB và use case từng loại - Tạo thử Application Load Balancer 19/11/2025 19/11/2025 AWS ELB Service Guide 3 - Thiết kế kiến trúc 3-tier Web → App → DB - Cấu hình load balancing Multi-AZ - Xây môi trường demo nhiều lớp 20/11/2025 20/11/2025 AWS Multi-Tier Architecture Notes 4 - Triển khai backup \u0026amp; restore cho RDS, EBS - Thử nghiệm cross-region replication - Lập kế hoạch DR Strategy 21/11/2025 21/11/2025 AWS DR Whitepaper 5 - Lab tổng hợp: + Build HA Web App trên AWS + ALB + Auto Scaling hoạt động ổn định + Multi-AZ RDS + Read Replica + Test failover DR scenario 22/11/2025 22/11/2025 FCJ Hands-on Workshop Week 11 Outcomes: Nắm rõ kiến trúc High Availability \u0026amp; Fault Tolerant trong thực tế. Tự cấu hình và thử nghiệm các loại Elastic Load Balancer. Hoàn thiện mô hình 3 lớp với khả năng mở rộng và chống lỗi. Xây dựng kế hoạch DR \u0026amp; sao lưu dữ liệu an toàn. Tạo được ứng dụng hoạt động bền vững khi xảy ra sự cố hệ thống. Summary: Kết thúc tuần này, tôi đã:\nBiết xây dựng hạ tầng web với HA đúng chuẩn AWS. Vận hành Application Load Balancer để phân phối traffic linh hoạt. Tạo kiến trúc web multi-tier có khả năng scale và multi-AZ. Cài đặt backup automation và cơ chế khôi phục sự cố (DR). Kiểm tra failover thực tế giúp hệ thống sẵn sàng chạy production. "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Hoàn thành capstone tổng hợp dựa trên toàn bộ kiến thức AWS đã học. Ôn tập và củng cố nội dung của 12 tuần đào tạo liên tục. Áp dụng best practices \u0026amp; Well-Architected Framework vào mô hình triển khai thật. Weekly Breakdown: Day Task Start Done References 1 Lên blueprint dự án: - Vẽ kiến trúc tổng quan - Xác định tài nguyên \u0026amp; dịch vụ AWS sử dụng - Viết checklist deploy 25/11/2025 25/11/2025 FCJ Architecture Notes 2 Triển khai phần nền tảng (Phase 1): - Xây VPC + Subnet + Routing - Tạo Auto Scaling Group \u0026amp; Load Balancer - Cấu hình RDS Multi-AZ 26/11/2025 26/11/2025 Previous Labs 3 Triển khai phần tối ưu (Phase 2): - Thêm Redis caching bằng ElastiCache - Tích hợp CDN với CloudFront + Route 53 - Tạo dashboard giám sát bằng CloudWatch 27/11/2025 27/11/2025 AWS Performance Guides 4 Tối ưu \u0026amp; hoàn thiện: - rà soát bảo mật, backup, chi phí - Cập nhật sơ đồ kiến trúc cuối - Ghi lại kinh nghiệm và lỗi đã gặp 28/11/2025 28/11/2025 Cost Optimization Reference 5 Tổng kết chương trình: + Làm đề luyện thi AWS SA Associate + Review các domain trong exam blueprint + Dọn tài nguyên AWS, tránh phát sinh phí + Chốt 12 tuần – tự thưởng bản thân 29/11/2025 29/11/2025 AWS Certification Prep Kit Week 12 Outcomes: Hoàn thiện capstone cloud architecture đa dịch vụ. Tự tổng hợp \u0026amp; kết nối hơn 3 tháng kiến thức AWS thành hệ thống thực tế. Nắm rõ quy trình thiết kế hệ thống bền vững, scale tốt, chi phí tối ưu. Viết xong tài liệu kiến trúc \u0026amp; hướng dẫn deploy chi tiết. Bắt đầu luyện thi chứng chỉ AWS chính thức. Final Reflection: Kết thúc tuần thứ 12:\nTôi đã có thể thiết kế \u0026amp; triển khai ứng dụng end-to-end trên AWS. Sử dụng thành thạo bộ dịch vụ: VPC, EC2, Auto Scaling, RDS, S3, CloudFront, Route 53… Biết áp dụng HA, DR, caching, multi-tier system vào thực tế dự án. Hiểu cách tối ưu tài nguyên, giám sát và đảm bảo chi phí hợp lý. Tự tin sẵn sàng tham gia hệ thống production thật sự trong tương lai. 12-Week Completion Summary: Dịch vụ đã học \u0026amp; thực hành: 15+ AWS Services\nNăng lực đạt được:\nAWS Account \u0026amp; Security Management (MFA, IAM, Budgets) Networking \u0026amp; Global Routing (VPC, Route 53, CloudFront) Compute (EC2, ASG, Lightsail, Elastic Load Balancer) Storage (S3, EBS) Databases (RDS, DynamoDB, Redis/ElastiCache) Monitoring (CloudWatch, AWS CLI) HA, Scalability \u0026amp; Fault Tolerance Design Windows Server \u0026amp; Directory Services on AWS CDN, Edge Functions \u0026amp; Performance Optimization Next Steps:\nPhát triển thêm dự án game tích hợp backend AWS Ôn thi AWS Solutions Architect Associate Học tiếp serverless stack: Lambda, API Gateway, Step Functions, EventBridge "
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://thienluhoan.github.io/workshop-template/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]